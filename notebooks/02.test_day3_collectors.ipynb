{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 3: 데이터 수집 파이프라인 테스트\n",
    "\n",
    "이 노트북은 Day 3에서 구현한 데이터 수집 API를 테스트합니다.\n",
    "\n",
    "## 테스트 항목\n",
    "1. Health Check\n",
    "2. 소스 목록 조회\n",
    "3. arXiv 논문 수집\n",
    "4. 뉴스 수집 (API 키 필요)\n",
    "5. 통합 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import requests\n",
    "\n",
    "# API Base URL\n",
    "BASE_URL = \"http://localhost:8000\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Health Check\n",
    "\n",
    "서버가 정상적으로 실행 중인지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Health check\n",
    "response = requests.get(f\"{BASE_URL}/health\")\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "print(\"Response:\")\n",
    "pprint(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 소스 목록 조회\n",
    "\n",
    "사용 가능한 모든 데이터 소스와 필터 옵션을 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get available sources\n",
    "response = requests.get(f\"{BASE_URL}/api/collectors/sources\")\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "print(\"\\nAvailable Sources:\")\n",
    "pprint(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. arXiv 논문 수집\n",
    "\n",
    "arXiv에서 논문을 검색하고 수집합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arXiv search - Basic\n",
    "payload = {\"query\": \"large language model\", \"limit\": 3}\n",
    "\n",
    "response = requests.post(f\"{BASE_URL}/api/collectors/arxiv\", json=payload)\n",
    "\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "data = response.json()\n",
    "print(f\"\\nTotal Results: {data['total']}\")\n",
    "print(f\"Errors: {data['errors']}\")\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "for i, item in enumerate(data[\"results\"], 1):\n",
    "    print(f\"\\n[{i}] {item['title']}\")\n",
    "    print(f\"    Source: {item['source_name']}\")\n",
    "    print(f\"    Type: {item['source_type']}\")\n",
    "    print(f\"    URL: {item['url']}\")\n",
    "    print(f\"    Content: {item['content'][:200]}...\")\n",
    "    print(f\"    Collected: {item['collected_at']}\")\n",
    "    print(\"    Metadata: \")\n",
    "    pprint(item[\"metadata\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arXiv search - With filters\n",
    "payload = {\n",
    "    \"query\": \"transformer\",\n",
    "    \"limit\": 5,\n",
    "    \"filters\": {\"categories\": [\"cs.AI\", \"cs.LG\"], \"sort_by\": \"relevance\", \"sort_order\": \"descending\"},\n",
    "}\n",
    "\n",
    "response = requests.post(f\"{BASE_URL}/api/collectors/arxiv\", json=payload)\n",
    "\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "data = response.json()\n",
    "print(f\"\\nTotal Results: {data['total']}\")\n",
    "\n",
    "# Display titles only\n",
    "print(\"\\nPapers found:\")\n",
    "for i, item in enumerate(data[\"results\"], 1):\n",
    "    print(f\"{i}. {item['title']}\")\n",
    "    print(f\"   Categories: {item['metadata']['categories']}\")\n",
    "    print(f\"   Authors: {', '.join(item['metadata']['authors'][:3])}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 뉴스 수집\n",
    "\n",
    "AI/테크 뉴스를 검색합니다. (Serper 또는 Brave API 키 필요)\n",
    "\n",
    "**주의**: 이 셀을 실행하려면 `.env` 파일에 `SERPER_API_KEY` 또는 `BRAVE_API_KEY`가 설정되어 있어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# News search\n",
    "payload = {\n",
    "    \"query\": \"artificial intelligence\",\n",
    "    \"limit\": 5,\n",
    "    \"filters\": {\n",
    "        \"domains\": [\"techcrunch.com\", \"venturebeat.com\"],\n",
    "        \"date_filter\": \"w\",  # Last week\n",
    "    },\n",
    "}\n",
    "\n",
    "response = requests.post(f\"{BASE_URL}/api/collectors/news\", json=payload)\n",
    "\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    print(f\"\\nTotal Results: {data['total']}\")\n",
    "    print(f\"Errors: {data['errors']}\")\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "    for i, item in enumerate(data[\"results\"], 1):\n",
    "        print(f\"\\n[{i}] {item['title']}\")\n",
    "        print(f\"    Source: {item['metadata'].get('source_name', 'N/A')}\")\n",
    "        print(f\"    URL: {item['url']}\")\n",
    "        print(f\"    Snippet: {item['content']}\")\n",
    "        print(f\"    Date: {item['metadata'].get('published_date', 'N/A')}\")\n",
    "else:\n",
    "    print(\"Error:\")\n",
    "    pprint(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 통합 검색\n",
    "\n",
    "여러 소스를 동시에 검색합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unified search - All sources\n",
    "payload = {\"query\": \"GPT-4\", \"limit\": 3}\n",
    "\n",
    "response = requests.post(f\"{BASE_URL}/api/collectors/search\", json=payload)\n",
    "\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "data = response.json()\n",
    "print(f\"\\nTotal Results: {data['total']}\")\n",
    "print(f\"Errors: {data['errors']}\")\n",
    "\n",
    "# Group by source\n",
    "by_source = {}\n",
    "for item in data[\"results\"]:\n",
    "    source = item[\"source_name\"]\n",
    "    if source not in by_source:\n",
    "        by_source[source] = []\n",
    "    by_source[source].append(item)\n",
    "\n",
    "print(\"\\nResults by source:\")\n",
    "for source, items in by_source.items():\n",
    "    print(f\"\\n{source}: {len(items)} items\")\n",
    "    for i, item in enumerate(items, 1):\n",
    "        print(f\"  {i}. {item['title'][:80]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unified search - Specific sources only\n",
    "payload = {\n",
    "    \"query\": \"machine learning\",\n",
    "    \"sources\": [\"arxiv\"],  # Only arXiv\n",
    "    \"limit\": 5,\n",
    "    \"filters\": {\"categories\": [\"cs.LG\", \"stat.ML\"]},\n",
    "}\n",
    "\n",
    "response = requests.post(f\"{BASE_URL}/api/collectors/search\", json=payload)\n",
    "\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "data = response.json()\n",
    "print(f\"\\nTotal Results: {data['total']}\")\n",
    "print(f\"Errors: {data['errors']}\")\n",
    "\n",
    "print(\"\\nPapers:\")\n",
    "for i, item in enumerate(data[\"results\"], 1):\n",
    "    print(f\"{i}. {item['title']}\")\n",
    "    print(f\"   URL: {item['url']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 에러 처리 테스트\n",
    "\n",
    "잘못된 요청에 대한 에러 처리를 테스트합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with invalid source\n",
    "payload = {\"query\": \"test\", \"sources\": [\"invalid_source\"], \"limit\": 5}\n",
    "\n",
    "response = requests.post(f\"{BASE_URL}/api/collectors/search\", json=payload)\n",
    "\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "data = response.json()\n",
    "print(\"\\nResponse:\")\n",
    "pprint(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with empty query\n",
    "payload = {\"query\": \"\", \"limit\": 5}\n",
    "\n",
    "response = requests.post(f\"{BASE_URL}/api/collectors/arxiv\", json=payload)\n",
    "\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "print(\"\\nResponse:\")\n",
    "pprint(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 성능 테스트\n",
    "\n",
    "API 응답 시간을 측정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Test arXiv performance\n",
    "payload = {\"query\": \"neural network\", \"limit\": 10}\n",
    "\n",
    "start = time.time()\n",
    "response = requests.post(f\"{BASE_URL}/api/collectors/arxiv\", json=payload)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "print(f\"Elapsed Time: {elapsed:.2f}s\")\n",
    "print(f\"Results: {response.json()['total']} items\")\n",
    "print(f\"Average time per item: {elapsed/response.json()['total']:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 데이터 분석\n",
    "\n",
    "수집된 데이터를 분석합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Collect more data for analysis\n",
    "payload = {\"query\": \"deep learning\", \"limit\": 20, \"filters\": {\"categories\": [\"cs.AI\", \"cs.LG\", \"cs.CV\"]}}\n",
    "\n",
    "response = requests.post(f\"{BASE_URL}/api/collectors/arxiv\", json=payload)\n",
    "\n",
    "data = response.json()\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_data = []\n",
    "for item in data[\"results\"]:\n",
    "    df_data.append(\n",
    "        {\n",
    "            \"title\": item[\"title\"],\n",
    "            \"url\": item[\"url\"],\n",
    "            \"source\": item[\"source_name\"],\n",
    "            \"primary_category\": item[\"metadata\"].get(\"primary_category\", \"N/A\"),\n",
    "            \"num_authors\": len(item[\"metadata\"].get(\"authors\", [])),\n",
    "            \"published\": item[\"metadata\"].get(\"published\", \"N/A\"),\n",
    "            \"content_length\": len(item[\"content\"]),\n",
    "        }\n",
    "    )\n",
    "\n",
    "df = pd.DataFrame(df_data)\n",
    "print(\"\\nDataFrame:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nStatistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\nCategory distribution:\")\n",
    "print(df[\"primary_category\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 시각화\n",
    "\n",
    "수집 결과를 시각화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot category distribution\n",
    "if len(df) > 0:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    df[\"primary_category\"].value_counts().plot(kind=\"bar\")\n",
    "    plt.title(\"arXiv Papers by Category\")\n",
    "    plt.xlabel(\"Category\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot content length distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(df[\"content_length\"], bins=20, edgecolor=\"black\")\n",
    "    plt.title(\"Abstract Length Distribution\")\n",
    "    plt.xlabel(\"Length (characters)\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결론\n",
    "\n",
    "Day 3 데이터 수집 파이프라인 테스트를 완료했습니다.\n",
    "\n",
    "### 테스트 결과 요약:\n",
    "- ✅ Health Check\n",
    "- ✅ 소스 목록 조회\n",
    "- ✅ arXiv 논문 수집\n",
    "- ✅ 필터링 및 정렬\n",
    "- ✅ 에러 처리\n",
    "- ✅ 통합 검색\n",
    "\n",
    "### 다음 단계 (Day 4):\n",
    "- LLM 기반 데이터 처리 (요약, 평가, 분류)\n",
    "- 임베딩 생성 및 Vector DB 저장"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
