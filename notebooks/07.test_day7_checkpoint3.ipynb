{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "## Day 7 Checkpoint 3: Full Pipeline Integration Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "logo",
   "metadata": {},
   "source": [
    "<img style=\"float: right;\" src=\"../img/logo.png\" width=\"120\"><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metadata",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <b>Research Curator Team</b></div>\n",
    "<div style=\"text-align: right\"> Initial issue : 2025.12.04 </div>\n",
    "<div style=\"text-align: right\"> last update : 2025.12.04 </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revision",
   "metadata": {},
   "source": [
    "ê°œì • ì´ë ¥  \n",
    "- `2025.12.04` : Full pipeline integration test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overview",
   "metadata": {},
   "source": [
    "### Overview: Full Pipeline Architecture\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  1. Collect     â”‚  â† ArXiv, News APIs\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "         â”‚\n",
    "         â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  2. Process     â”‚  â† LLM (Summarize, Score, Classify)\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "         â”‚\n",
    "         â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  3. Store       â”‚  â† PostgreSQL + Qdrant\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "         â”‚\n",
    "         â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  4. Curate      â”‚  â† Select top N articles\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "         â”‚\n",
    "         â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  5. Send Email  â”‚  â† SMTP\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step1",
   "metadata": {},
   "source": [
    "### Step 1: Setup Test Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import UTC, datetime\n",
    "from app.db import crud\n",
    "from app.db.session import SessionLocal\n",
    "from app.scheduler.tasks import collect_data_task, process_articles_task\n",
    "\n",
    "print(\"âœ… Imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_user",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test user and preferences\n",
    "db = SessionLocal()\n",
    "\n",
    "test_user = crud.create_user(\n",
    "    db=db,\n",
    "    email=\"integration_test@example.com\",\n",
    "    name=\"Integration Test User\"\n",
    ")\n",
    "\n",
    "crud.create_user_preference(\n",
    "    db=db,\n",
    "    user_id=test_user.id,\n",
    "    research_fields=[\"Machine Learning\", \"Natural Language Processing\", \"Computer Vision\"],\n",
    "    keywords=[\"transformer\", \"attention mechanism\", \"large language model\", \"GPT\", \"BERT\"],\n",
    "    email_time=\"09:00\",\n",
    "    daily_limit=10,\n",
    "    email_enabled=False,  # Disable actual email sending\n",
    ")\n",
    "\n",
    "print(f\"âœ… Created test user: {test_user.email}\")\n",
    "print(f\"User ID: {test_user.id}\")\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step2",
   "metadata": {},
   "source": [
    "### Step 2: Data Collection\n",
    "\n",
    "Collect articles from arXiv and News sources based on user preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "check_initial_state",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = SessionLocal()\n",
    "\n",
    "initial_count = crud.count_articles(db)\n",
    "print(f\"Initial article count: {initial_count}\")\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run_collection",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting data collection...\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "collect_data_task()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"âœ… Data collection completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verify_collection",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = SessionLocal()\n",
    "\n",
    "after_count = crud.count_articles(db)\n",
    "collected = after_count - initial_count\n",
    "\n",
    "print(f\"Articles after collection: {after_count}\")\n",
    "print(f\"Newly collected: {collected}\")\n",
    "\n",
    "# Show sample articles\n",
    "if collected > 0:\n",
    "    print(\"\\nSample collected articles:\\n\")\n",
    "    recent = crud.list_articles(db, limit=5)\n",
    "    for i, article in enumerate(recent[:5], 1):\n",
    "        print(f\"{i}. {article.title[:70]}\")\n",
    "        print(f\"   Type: {article.source_type} | Category: {article.category or 'Not set'}\")\n",
    "        print(f\"   URL: {article.source_url[:60]}...\")\n",
    "        print()\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step3",
   "metadata": {},
   "source": [
    "### Step 3: Article Processing\n",
    "\n",
    "Process collected articles with LLM:\n",
    "1. Generate Korean summaries\n",
    "2. Evaluate importance scores\n",
    "3. Classify categories\n",
    "4. Generate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "check_unprocessed",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = SessionLocal()\n",
    "\n",
    "all_articles = crud.list_articles(db, limit=100)\n",
    "unprocessed = [a for a in all_articles if not a.summary or a.importance_score is None]\n",
    "\n",
    "print(f\"Total articles: {len(all_articles)}\")\n",
    "print(f\"Unprocessed articles: {len(unprocessed)}\")\n",
    "\n",
    "if len(unprocessed) > 0:\n",
    "    print(\"\\nSample unprocessed articles:\")\n",
    "    for i, article in enumerate(unprocessed[:3], 1):\n",
    "        print(f\"{i}. {article.title[:60]}\")\n",
    "        print(f\"   Has summary: {article.summary is not None}\")\n",
    "        print(f\"   Has score: {article.importance_score is not None}\")\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run_processing",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(unprocessed) > 0:\n",
    "    print(\"Starting article processing...\\n\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    process_articles_task()\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"âœ… Article processing completed!\")\n",
    "else:\n",
    "    print(\"âš ï¸ No unprocessed articles found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verify_processing",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = SessionLocal()\n",
    "\n",
    "processed_articles = crud.list_articles(db, limit=5)\n",
    "print(\"Sample processed articles:\\n\")\n",
    "\n",
    "for i, article in enumerate(processed_articles, 1):\n",
    "    print(f\"{i}. {article.title[:60]}\")\n",
    "    print(f\"   Summary: {article.summary[:80] if article.summary else 'None'}...\")\n",
    "    print(f\"   Importance: {article.importance_score}\")\n",
    "    print(f\"   Category: {article.category}\")\n",
    "    print(f\"   Vector ID: {article.vector_id[:20] if article.vector_id else 'None'}...\")\n",
    "    print()\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step4",
   "metadata": {},
   "source": [
    "### Step 4: Data Analysis & Curation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyze_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = SessionLocal()\n",
    "\n",
    "# Statistics\n",
    "total = crud.count_articles(db)\n",
    "papers = crud.count_articles(db, source_type=\"paper\")\n",
    "news = crud.count_articles(db, source_type=\"news\")\n",
    "\n",
    "print(\"ğŸ“Š Database Statistics\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Total articles: {total}\")\n",
    "print(f\"Papers: {papers}\")\n",
    "print(f\"News: {news}\")\n",
    "\n",
    "# Top articles by importance\n",
    "top_articles = crud.get_top_articles_by_importance(db, limit=10)\n",
    "print(f\"\\nğŸ† Top 10 Articles by Importance\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for i, article in enumerate(top_articles, 1):\n",
    "    print(f\"{i}. [{article.importance_score:.3f}] {article.title[:55]}\")\n",
    "    print(f\"   {article.source_type.upper()} | {article.category}\")\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step5",
   "metadata": {},
   "source": [
    "### Step 5: Digest Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_digest",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = SessionLocal()\n",
    "\n",
    "# Get top 5 articles for digest\n",
    "top_5 = crud.get_top_articles_by_importance(db, limit=5)\n",
    "\n",
    "if len(top_5) > 0:\n",
    "    # Create digest record\n",
    "    digest = crud.create_digest(\n",
    "        db=db,\n",
    "        user_id=test_user.id,\n",
    "        article_ids=[str(a.id) for a in top_5],\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… Created digest: {digest.id}\")\n",
    "    print(f\"Articles in digest: {len(digest.article_ids)}\")\n",
    "    print(f\"Sent at: {digest.sent_at}\")\n",
    "    print(f\"\\nDigest contents:\")\n",
    "    \n",
    "    for i, article in enumerate(top_5, 1):\n",
    "        print(f\"\\n{i}. {article.title}\")\n",
    "        print(f\"   Score: {article.importance_score:.3f}\")\n",
    "        print(f\"   Summary: {article.summary[:100]}...\" if article.summary else \"   No summary\")\n",
    "else:\n",
    "    print(\"âš ï¸ No articles available for digest\")\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step6",
   "metadata": {},
   "source": [
    "### Step 6: Verify Relationships & Data Integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verify_relationships",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = SessionLocal()\n",
    "\n",
    "# Get user with all relationships\n",
    "user = crud.get_user_by_id(db, test_user.id)\n",
    "\n",
    "print(\"User Relationships:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"User: {user.email}\")\n",
    "print(f\"Has preference: {user.preference is not None}\")\n",
    "if user.preference:\n",
    "    print(f\"  Research fields: {user.preference.research_fields}\")\n",
    "    print(f\"  Keywords: {user.preference.keywords}\")\n",
    "    print(f\"  Daily limit: {user.preference.daily_limit}\")\n",
    "\n",
    "print(f\"\\nDigests: {len(user.digests)}\")\n",
    "for digest in user.digests:\n",
    "    print(f\"  - {digest.sent_at}: {len(digest.article_ids)} articles\")\n",
    "\n",
    "print(f\"\\nFeedbacks: {len(user.feedbacks)}\")\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step7",
   "metadata": {},
   "source": [
    "### Step 7: Pipeline Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "performance_metrics",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = SessionLocal()\n",
    "\n",
    "# Calculate metrics\n",
    "all_articles = crud.list_articles(db, limit=100)\n",
    "has_summary = sum(1 for a in all_articles if a.summary)\n",
    "has_score = sum(1 for a in all_articles if a.importance_score is not None)\n",
    "has_category = sum(1 for a in all_articles if a.category)\n",
    "has_vector = sum(1 for a in all_articles if a.vector_id)\n",
    "\n",
    "total = len(all_articles)\n",
    "\n",
    "print(\"ğŸ“ˆ Pipeline Performance Metrics\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Total articles: {total}\")\n",
    "print(f\"\\nProcessing completion rates:\")\n",
    "print(f\"  Summarization: {has_summary}/{total} ({has_summary/total*100:.1f}%)\" if total > 0 else \"  Summarization: N/A\")\n",
    "print(f\"  Importance scoring: {has_score}/{total} ({has_score/total*100:.1f}%)\" if total > 0 else \"  Importance scoring: N/A\")\n",
    "print(f\"  Categorization: {has_category}/{total} ({has_category/total*100:.1f}%)\" if total > 0 else \"  Categorization: N/A\")\n",
    "print(f\"  Embedding generation: {has_vector}/{total} ({has_vector/total*100:.1f}%)\" if total > 0 else \"  Embedding generation: N/A\")\n",
    "\n",
    "# Average importance score\n",
    "if has_score > 0:\n",
    "    avg_score = sum(a.importance_score for a in all_articles if a.importance_score) / has_score\n",
    "    print(f\"\\nAverage importance score: {avg_score:.3f}\")\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleanup",
   "metadata": {},
   "source": [
    "### Cleanup (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleanup_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to clean up test data\n",
    "# db = SessionLocal()\n",
    "# crud.delete_user(db, test_user.id)  # Cascade deletes preferences and digests\n",
    "# print(\"âœ… Test user and related data deleted\")\n",
    "# db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "âœ… **Checkpoint 3 ì™„ë£Œ!**\n",
    "\n",
    "ì „ì²´ íŒŒì´í”„ë¼ì¸ í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ:\n",
    "1. âœ… ë°ì´í„° ìˆ˜ì§‘ (arXiv + News)\n",
    "2. âœ… LLM ì²˜ë¦¬ (ìš”ì•½, í‰ê°€, ë¶„ë¥˜)\n",
    "3. âœ… ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥\n",
    "4. âœ… ì„ë² ë”© ìƒì„±\n",
    "5. âœ… ë‹¤ì´ì œìŠ¤íŠ¸ íë ˆì´ì…˜\n",
    "6. âœ… ê´€ê³„ ê²€ì¦\n",
    "7. âœ… ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë¶„ì„\n",
    "\n",
    "**ëª¨ë“  íŒŒì´í”„ë¼ì¸ ì»´í¬ë„ŒíŠ¸ê°€ ì •ìƒì ìœ¼ë¡œ í†µí•©ë˜ì–´ ì‘ë™í•©ë‹ˆë‹¤!**\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- ì‹¤ì œ ìŠ¤ì¼€ì¤„ì— ë”°ë¥¸ ìë™ ì‹¤í–‰ í…ŒìŠ¤íŠ¸\n",
    "- ì´ë©”ì¼ ë°œì†¡ ê¸°ëŠ¥ ì™„ì„± (SMTP ì„¤ì •)\n",
    "- í”„ë¡ íŠ¸ì—”ë“œ êµ¬í˜„ (Streamlit)\n",
    "- Vector DB ê²€ìƒ‰ ê¸°ëŠ¥ ê°•í™”"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
