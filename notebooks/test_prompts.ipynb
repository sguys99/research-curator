{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ `configs/prompts.yaml`ê³¼ `src/app/core/prompts.py`ì˜ ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import json\n",
    "\n",
    "from src.app.core.prompts import build_messages, get_prompt, get_prompt_manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. PromptManager ì´ˆê¸°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PromptManager ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°\n",
    "manager = get_prompt_manager()\n",
    "\n",
    "print(\"âœ… PromptManager ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "print(f\"í”„ë¡¬í”„íŠ¸ íŒŒì¼ ê²½ë¡œ: {manager.prompts_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ì¹´í…Œê³ ë¦¬ ë° ì˜µì…˜ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´í…Œê³ ë¦¬:\")\n",
    "for cat in manager.get_categories():\n",
    "    print(f\"  - {cat}\")\n",
    "\n",
    "print(\"\\nğŸ“ ìš”ì•½ ê¸¸ì´ ì˜µì…˜:\")\n",
    "for length in manager.get_summary_lengths():\n",
    "    print(f\"  - {length}\")\n",
    "\n",
    "print(\"\\nğŸ·ï¸ ë¶„ë¥˜ ì¹´í…Œê³ ë¦¬:\")\n",
    "for cat in manager.get_classification_categories():\n",
    "    print(f\"  - {cat}\")\n",
    "\n",
    "print(\"\\nğŸ”¬ ì—°êµ¬ ë¶„ì•¼:\")\n",
    "for field in manager.get_research_fields():\n",
    "    print(f\"  - {field}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ìš”ì•½ í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒ˜í”Œ ë…¼ë¬¸ ë°ì´í„°\n",
    "sample_article = {\n",
    "    \"title\": \"Attention Is All You Need\",\n",
    "    \"content\": \"\"\"\n",
    "    We propose a new simple network architecture, the Transformer, \n",
    "    based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.\n",
    "    Experiments on two machine translation tasks show these models to be superior in quality \n",
    "    while being more parallelizable and requiring significantly less time to train.\n",
    "    \"\"\",\n",
    "}\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ìš”ì•½ í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸ (í•œêµ­ì–´ - Medium)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "messages = manager.build_messages(\n",
    "    \"summarize\", \"korean.medium\", title=sample_article[\"title\"], content=sample_article[\"content\"]\n",
    ")\n",
    "\n",
    "print(\"\\n[System Prompt]\")\n",
    "print(messages[0][\"content\"])\n",
    "print(\"\\n[User Prompt]\")\n",
    "print(messages[1][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‹¤ë¥¸ ê¸¸ì´ ì˜µì…˜ í…ŒìŠ¤íŠ¸\n",
    "print(\"=\" * 60)\n",
    "print(\"ìš”ì•½ í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸ (í•œêµ­ì–´ - Short)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "messages_short = manager.build_messages(\n",
    "    \"summarize\", \"korean.short\", title=sample_article[\"title\"], content=sample_article[\"content\"]\n",
    ")\n",
    "\n",
    "print(\"\\n[User Prompt]\")\n",
    "print(messages_short[1][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ì¤‘ìš”ë„ í‰ê°€ í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"ì¤‘ìš”ë„ í‰ê°€ í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "eval_messages = manager.build_messages(\n",
    "    \"evaluate_importance\",\n",
    "    title=sample_article[\"title\"],\n",
    "    content=sample_article[\"content\"],\n",
    "    metadata=json.dumps({\"citations\": 50000, \"year\": 2017}),\n",
    ")\n",
    "\n",
    "print(\"\\n[System Prompt]\")\n",
    "print(eval_messages[0][\"content\"][:300], \"...\")\n",
    "print(\"\\n[User Prompt]\")\n",
    "print(eval_messages[1][\"content\"][:300], \"...\")\n",
    "\n",
    "# í‰ê°€ ê¸°ì¤€ ë° ê°€ì¤‘ì¹˜\n",
    "print(\"\\nğŸ“Š í‰ê°€ ê¸°ì¤€:\")\n",
    "criteria = manager.get_evaluation_criteria()\n",
    "weights = manager.get_evaluation_weights()\n",
    "for criterion in criteria:\n",
    "    weight = weights.get(criterion, 0)\n",
    "    print(f\"  - {criterion}: {weight * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "classify_messages = manager.build_messages(\n",
    "    \"classify_category\",\n",
    "    title=sample_article[\"title\"],\n",
    "    content=sample_article[\"content\"],\n",
    "    source_name=\"arXiv\",\n",
    "    url=\"https://arxiv.org/abs/1706.03762\",\n",
    ")\n",
    "\n",
    "print(\"\\n[System Prompt]\")\n",
    "print(classify_messages[0][\"content\"][:300], \"...\")\n",
    "print(\"\\n[User Prompt]\")\n",
    "print(classify_messages[1][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. í”„ë¡¬í”„íŠ¸ í¬ë§·íŒ… í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"í”„ë¡¬í”„íŠ¸ í¬ë§·íŒ… í…ŒìŠ¤íŠ¸\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "template = manager.get(\"summarize.korean.medium.user_template\")\n",
    "\n",
    "# ë³€ìˆ˜ ì¹˜í™˜\n",
    "formatted = manager.format_prompt(\n",
    "    template, title=\"GPT-4 Technical Report\", content=\"GPT-4ëŠ” ëŒ€ê·œëª¨ ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ì…ë‹ˆë‹¤...\"\n",
    ")\n",
    "\n",
    "print(\"\\n[ì›ë³¸ í…œí”Œë¦¿]\")\n",
    "print(template[:200], \"...\")\n",
    "print(\"\\n[í¬ë§·ëœ ê²°ê³¼]\")\n",
    "print(formatted[:200], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ì˜¨ë³´ë”© í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"ì˜¨ë³´ë”© ì±—ë´‡ í”„ë¡¬í”„íŠ¸\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# í™˜ì˜ ë©”ì‹œì§€\n",
    "welcome = get_prompt(\"onboarding.welcome_message\")\n",
    "print(\"\\n[í™˜ì˜ ë©”ì‹œì§€]\")\n",
    "print(welcome)\n",
    "\n",
    "# ì§ˆë¬¸ ëª©ë¡\n",
    "print(\"\\n[ì§ˆë¬¸ ëª©ë¡]\")\n",
    "questions = get_prompt(\"onboarding.questions\")\n",
    "for key, value in questions.items():\n",
    "    print(f\"\\n{key}:\")\n",
    "    print(f\"  {value['prompt'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. í¸ì˜ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"í¸ì˜ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# get_prompt í•¨ìˆ˜\n",
    "default_lang = get_prompt(\"common.default_language\")\n",
    "print(f\"\\nê¸°ë³¸ ì–¸ì–´: {default_lang}\")\n",
    "\n",
    "# build_messages í•¨ìˆ˜ (ì§ì ‘ í˜¸ì¶œ)\n",
    "messages = build_messages(\"summarize\", \"english.short\", title=\"Test\", content=\"Test content\")\n",
    "print(f\"\\nì˜ì–´ ìš”ì•½ ë©”ì‹œì§€ ìƒì„± ì„±ê³µ: {len(messages)} messages\")\n",
    "\n",
    "# ì—ëŸ¬ ë©”ì‹œì§€\n",
    "error_msgs = get_prompt(\"common.error_messages\")\n",
    "print(\"\\nì—ëŸ¬ ë©”ì‹œì§€:\")\n",
    "for key, value in error_msgs.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ì¢…í•© í…ŒìŠ¤íŠ¸\n",
    "\n",
    "ì‹¤ì œ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤: ë…¼ë¬¸ í•˜ë‚˜ë¥¼ ë°›ì•„ì„œ ëª¨ë“  ì²˜ë¦¬ë¥¼ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"ì¢…í•© í…ŒìŠ¤íŠ¸: ì‹¤ì œ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ì‹¤ì œ ë…¼ë¬¸ ë°ì´í„°\n",
    "article = {\n",
    "    \"title\": \"Language Models are Few-Shot Learners\",\n",
    "    \"content\": \"\"\"\n",
    "    We demonstrate that scaling up language models greatly improves task-agnostic, \n",
    "    few-shot performance. We train GPT-3, an autoregressive language model with 175 billion parameters,\n",
    "    and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any \n",
    "    gradient updates or fine-tuning.\n",
    "    \"\"\",\n",
    "    \"source_name\": \"arXiv\",\n",
    "    \"url\": \"https://arxiv.org/abs/2005.14165\",\n",
    "    \"metadata\": {\"citations\": 15000, \"year\": 2020},\n",
    "}\n",
    "\n",
    "# 1. ìš”ì•½ í”„ë¡¬í”„íŠ¸\n",
    "print(\"\\n1ï¸âƒ£ ìš”ì•½ ìƒì„± í”„ë¡¬í”„íŠ¸\")\n",
    "summary_msgs = build_messages(\n",
    "    \"summarize\", \"korean.medium\", title=article[\"title\"], content=article[\"content\"]\n",
    ")\n",
    "print(f\"âœ… ë©”ì‹œì§€ ìƒì„± ì™„ë£Œ ({len(summary_msgs)} messages)\")\n",
    "\n",
    "# 2. ì¤‘ìš”ë„ í‰ê°€ í”„ë¡¬í”„íŠ¸\n",
    "print(\"\\n2ï¸âƒ£ ì¤‘ìš”ë„ í‰ê°€ í”„ë¡¬í”„íŠ¸\")\n",
    "eval_msgs = build_messages(\n",
    "    \"evaluate_importance\",\n",
    "    title=article[\"title\"],\n",
    "    content=article[\"content\"],\n",
    "    metadata=json.dumps(article[\"metadata\"]),\n",
    ")\n",
    "print(f\"âœ… ë©”ì‹œì§€ ìƒì„± ì™„ë£Œ ({len(eval_msgs)} messages)\")\n",
    "\n",
    "# 3. ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ í”„ë¡¬í”„íŠ¸\n",
    "print(\"\\n3ï¸âƒ£ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ í”„ë¡¬í”„íŠ¸\")\n",
    "classify_msgs = build_messages(\n",
    "    \"classify_category\",\n",
    "    title=article[\"title\"],\n",
    "    content=article[\"content\"],\n",
    "    source_name=article[\"source_name\"],\n",
    "    url=article[\"url\"],\n",
    ")\n",
    "print(f\"âœ… ë©”ì‹œì§€ ìƒì„± ì™„ë£Œ ({len(classify_msgs)} messages)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"âœ… ëª¨ë“  í”„ë¡¬í”„íŠ¸ ìƒì„± ì„±ê³µ!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… Checkpoint 1 í™•ì¸\n",
    "\n",
    "- [x] `configs/prompts.yaml` ì¡´ì¬\n",
    "- [x] í”„ë¡¬í”„íŠ¸ ë¡œë” ì •ìƒ ì‘ë™\n",
    "- [x] í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë³€ìˆ˜ ì¹˜í™˜ í…ŒìŠ¤íŠ¸ ì„±ê³µ\n",
    "\n",
    "**Step 1 ì™„ë£Œ!** ë‹¤ìŒ Step 2ë¡œ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
