{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "## Day 7: Scheduler & Automation Pipeline Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "logo",
   "metadata": {},
   "source": [
    "<img style=\"float: right;\" src=\"../img/logo.png\" width=\"120\"><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metadata",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <b>Research Curator Team</b></div>\n",
    "<div style=\"text-align: right\"> Initial issue : 2025.12.04 </div>\n",
    "<div style=\"text-align: right\"> last update : 2025.12.04 </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revision",
   "metadata": {},
   "source": [
    "ê°œì • ì´ë ¥  \n",
    "- `2025.12.04` : Day 7 í†µí•© í…ŒìŠ¤íŠ¸ (4ê°œ Checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "print(\"âœ… Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overview",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Day 7ì—ì„œëŠ” 4ê°œì˜ Checkpointë¥¼ í†µí•´ ì „ì²´ ìë™í™” íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•˜ê³  í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤:\n",
    "\n",
    "1. **Checkpoint 1**: Database Models & CRUD Operations\n",
    "2. **Checkpoint 2**: Scheduler & Scheduled Tasks\n",
    "3. **Checkpoint 3**: Full Pipeline Integration\n",
    "4. **Checkpoint 4**: Scheduler API & Monitoring\n",
    "\n",
    "### Full Pipeline Architecture\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  1. Collect     â”‚  â† ArXiv, News APIs (01:00 KST)\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "         â”‚\n",
    "         â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  2. Process     â”‚  â† LLM (Summarize, Score, Classify) (01:30 KST)\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "         â”‚\n",
    "         â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  3. Store       â”‚  â† PostgreSQL + Qdrant\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "         â”‚\n",
    "         â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  4. Curate      â”‚  â† Select top N articles\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "         â”‚\n",
    "         â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  5. Send Email  â”‚  â† SMTP (08:00 KST)\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "         â”‚\n",
    "         â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  6. Monitor     â”‚  â† REST API\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checkpoint1_header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Checkpoint 1: Database Models & CRUD Operations\n",
    "\n",
    "ë°ì´í„°ë² ì´ìŠ¤ ëª¨ë¸ì˜ ê´€ê³„ ì„¤ì • ë° CRUD ì‘ì—…ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cp1_step1",
   "metadata": {},
   "source": [
    "### 1.1 Database Connection Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_connection",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.core.config import settings\n",
    "from app.db.session import SessionLocal, engine\n",
    "\n",
    "print(f\"Database URL: {settings.database_url_str}\")\n",
    "print(f\"Engine: {engine}\")\n",
    "\n",
    "# Test connection\n",
    "try:\n",
    "    with engine.connect() as conn:\n",
    "        print(\"âœ… Database connection successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Database connection failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cp1_step2",
   "metadata": {},
   "source": [
    "### 1.2 User CRUD Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_user_crud",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.db import crud\n",
    "from app.db.session import SessionLocal\n",
    "\n",
    "db = SessionLocal()\n",
    "\n",
    "# Create user\n",
    "test_user = crud.create_user(\n",
    "    db=db,\n",
    "    email=\"test@example.com\",\n",
    "    name=\"Test User\"\n",
    ")\n",
    "\n",
    "print(f\"âœ… Created user: {test_user.email}\")\n",
    "print(f\"   User ID: {test_user.id}\")\n",
    "\n",
    "user_id = test_user.id\n",
    "\n",
    "# Read user\n",
    "user = crud.get_user_by_email(db, \"test@example.com\")\n",
    "print(f\"âœ… Retrieved user: {user.name}\")\n",
    "\n",
    "# Update user\n",
    "updated_user = crud.update_user(db, user_id, name=\"Updated Test User\")\n",
    "print(f\"âœ… Updated user name: {updated_user.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cp1_step3",
   "metadata": {},
   "source": [
    "### 1.3 UserPreference CRUD Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_preference_crud",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preferences\n",
    "preference = crud.create_user_preference(\n",
    "    db=db,\n",
    "    user_id=user_id,\n",
    "    research_fields=[\"Machine Learning\", \"NLP\"],\n",
    "    keywords=[\"transformers\", \"attention\", \"LLM\"],\n",
    "    sources={\"arxiv\": True, \"google_scholar\": True},\n",
    "    info_types={\"paper\": 50, \"news\": 30, \"report\": 20},\n",
    "    email_time=\"09:00\",\n",
    "    daily_limit=10,\n",
    ")\n",
    "\n",
    "print(f\"âœ… Created preference\")\n",
    "print(f\"   Research fields: {preference.research_fields}\")\n",
    "print(f\"   Keywords: {preference.keywords}\")\n",
    "\n",
    "# Update preferences\n",
    "updated_pref = crud.update_user_preference(\n",
    "    db, user_id,\n",
    "    keywords=[\"transformers\", \"attention\", \"LLM\", \"GPT\"],\n",
    "    daily_limit=15,\n",
    ")\n",
    "print(f\"âœ… Updated preference\")\n",
    "print(f\"   New keywords: {updated_pref.keywords}\")\n",
    "print(f\"   New daily limit: {updated_pref.daily_limit}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cp1_step4",
   "metadata": {},
   "source": [
    "### 1.4 CollectedArticle CRUD Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_article_crud",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, UTC\n",
    "\n",
    "# Create articles\n",
    "article1 = crud.create_article(\n",
    "    db=db,\n",
    "    title=\"Attention Is All You Need\",\n",
    "    content=\"Full paper content here...\",\n",
    "    summary=\"í˜ì‹ ì ì¸ Transformer ì•„í‚¤í…ì²˜ë¥¼ ì†Œê°œí•˜ëŠ” ë…¼ë¬¸ì…ë‹ˆë‹¤.\",\n",
    "    source_url=\"https://arxiv.org/abs/1706.03762\",\n",
    "    source_type=\"paper\",\n",
    "    category=\"Deep Learning\",\n",
    "    importance_score=0.95,\n",
    "    article_metadata={\"authors\": [\"Vaswani et al.\"], \"citations\": 90000},\n",
    "    published_at=datetime.now(UTC),\n",
    ")\n",
    "\n",
    "article2 = crud.create_article(\n",
    "    db=db,\n",
    "    title=\"GPT-4 Technical Report\",\n",
    "    content=\"Technical report content...\",\n",
    "    summary=\"OpenAIì˜ ìµœì‹  ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì— ëŒ€í•œ ê¸°ìˆ  ë¦¬í¬íŠ¸ì…ë‹ˆë‹¤.\",\n",
    "    source_url=\"https://arxiv.org/abs/2303.08774\",\n",
    "    source_type=\"paper\",\n",
    "    category=\"LLM\",\n",
    "    importance_score=0.98,\n",
    ")\n",
    "\n",
    "article3 = crud.create_article(\n",
    "    db=db,\n",
    "    title=\"AI News: New Breakthrough\",\n",
    "    content=\"News article content...\",\n",
    "    source_url=\"https://techcrunch.com/ai-breakthrough\",\n",
    "    source_type=\"news\",\n",
    "    importance_score=0.75,\n",
    ")\n",
    "\n",
    "print(f\"âœ… Created 3 articles\")\n",
    "article_id = article1.id\n",
    "\n",
    "# List and filter articles\n",
    "all_articles = crud.list_articles(db, limit=10)\n",
    "print(f\"âœ… Total articles: {len(all_articles)}\")\n",
    "\n",
    "papers = crud.list_articles(db, source_type=\"paper\")\n",
    "print(f\"âœ… Papers only: {len(papers)}\")\n",
    "\n",
    "top_articles = crud.get_top_articles_by_importance(db, limit=5)\n",
    "print(f\"âœ… Top 5 articles by importance:\")\n",
    "for a in top_articles:\n",
    "    print(f\"   - {a.title[:50]}... (score: {a.importance_score})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cp1_step5",
   "metadata": {},
   "source": [
    "### 1.5 SentDigest & Feedback CRUD Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_digest_feedback",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create digest\n",
    "digest = crud.create_digest(\n",
    "    db=db,\n",
    "    user_id=user_id,\n",
    "    article_ids=[str(article1.id), str(article2.id)],\n",
    ")\n",
    "print(f\"âœ… Created digest: {digest.id}\")\n",
    "print(f\"   Articles: {len(digest.article_ids)}\")\n",
    "\n",
    "digest_id = digest.id\n",
    "\n",
    "# Create feedback\n",
    "feedback1 = crud.create_feedback(\n",
    "    db=db,\n",
    "    user_id=user_id,\n",
    "    article_id=article1.id,\n",
    "    rating=5,\n",
    "    comment=\"Excellent paper!\",\n",
    ")\n",
    "print(f\"âœ… Created feedback: rating {feedback1.rating}\")\n",
    "\n",
    "# Get average rating\n",
    "avg_rating = crud.get_article_average_rating(db, article1.id)\n",
    "print(f\"âœ… Average rating: {avg_rating}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cp1_step6",
   "metadata": {},
   "source": [
    "### 1.6 Test Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_relationships",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test User â†’ Preference, Digests, Feedbacks\n",
    "user = crud.get_user_by_id(db, user_id)\n",
    "print(f\"User: {user.email}\")\n",
    "print(f\"âœ… Has preference: {user.preference is not None}\")\n",
    "print(f\"âœ… Digests: {len(user.digests)}\")\n",
    "print(f\"âœ… Feedbacks: {len(user.feedbacks)}\")\n",
    "\n",
    "# Test Article â†’ Feedbacks\n",
    "article = crud.get_article_by_id(db, article1.id)\n",
    "print(f\"\\nArticle: {article.title}\")\n",
    "print(f\"âœ… Feedbacks: {len(article.feedbacks)}\")\n",
    "\n",
    "print(\"\\nâœ… All relationships working correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cp1_summary",
   "metadata": {},
   "source": [
    "### âœ… Checkpoint 1 ì™„ë£Œ!\n",
    "\n",
    "- Database connection\n",
    "- User, UserPreference, CollectedArticle, SentDigest, Feedback CRUD\n",
    "- Relationships (1:1, 1:N) ë° CASCADE ì‚­ì œ\n",
    "- Filtering, Sorting, Pagination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checkpoint2_header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Checkpoint 2: Scheduler & Scheduled Tasks\n",
    "\n",
    "APSchedulerë¥¼ ì‚¬ìš©í•œ ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì • ë° íƒœìŠ¤í¬ ì‹¤í–‰ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cp2_step1",
   "metadata": {},
   "source": [
    "### 2.1 Scheduler Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import_scheduler",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.scheduler.main import (\n",
    "    start_scheduler,\n",
    "    stop_scheduler,\n",
    "    get_scheduler_status,\n",
    "    trigger_job_manually,\n",
    "    scheduler,\n",
    ")\n",
    "\n",
    "print(\"âœ… Scheduler imported successfully!\")\n",
    "\n",
    "# Start scheduler\n",
    "start_scheduler()\n",
    "\n",
    "# Check status\n",
    "status = get_scheduler_status()\n",
    "print(f\"\\nâœ… Scheduler running: {status['running']}\")\n",
    "print(f\"   Timezone: {status['timezone']}\")\n",
    "print(f\"   Jobs: {len(status['jobs'])}\")\n",
    "\n",
    "print(\"\\nScheduled Jobs:\")\n",
    "for job in status['jobs']:\n",
    "    print(f\"\\n  - {job['name']} (ID: {job['id']})\")\n",
    "    print(f\"    Next run: {job['next_run_time']}\")\n",
    "    print(f\"    Trigger: {job['trigger']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cp2_step2",
   "metadata": {},
   "source": [
    "### 2.2 Test Data Collection Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_collect_task",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.scheduler.tasks import collect_data_task\n",
    "\n",
    "# Check initial count\n",
    "initial_count = crud.count_articles(db)\n",
    "print(f\"Initial article count: {initial_count}\")\n",
    "\n",
    "# Run collection task\n",
    "print(\"\\nRunning data collection task...\")\n",
    "print(\"=\" * 60)\n",
    "collect_data_task()\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check after count\n",
    "after_count = crud.count_articles(db)\n",
    "collected = after_count - initial_count\n",
    "print(f\"\\nâœ… Data collection completed!\")\n",
    "print(f\"   Articles collected: {collected}\")\n",
    "print(f\"   Total articles: {after_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cp2_step3",
   "metadata": {},
   "source": [
    "### 2.3 Test Article Processing Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_process_task",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.scheduler.tasks import process_articles_task\n",
    "\n",
    "# Check unprocessed articles\n",
    "all_articles = crud.list_articles(db, limit=100)\n",
    "unprocessed = [a for a in all_articles if not a.summary or a.importance_score is None]\n",
    "print(f\"Unprocessed articles: {len(unprocessed)}\")\n",
    "\n",
    "if len(unprocessed) > 0:\n",
    "    print(\"\\nRunning article processing task...\")\n",
    "    print(\"=\" * 60)\n",
    "    process_articles_task()\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\nâœ… Article processing completed!\")\n",
    "    \n",
    "    # Show processed articles\n",
    "    processed_articles = crud.list_articles(db, limit=3)\n",
    "    print(\"\\nSample processed articles:\")\n",
    "    for i, article in enumerate(processed_articles, 1):\n",
    "        print(f\"\\n{i}. {article.title[:60]}...\")\n",
    "        print(f\"   Summary: {article.summary[:80] if article.summary else 'None'}...\")\n",
    "        print(f\"   Importance: {article.importance_score}\")\n",
    "        print(f\"   Category: {article.category}\")\n",
    "else:\n",
    "    print(\"âš ï¸ No unprocessed articles found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cp2_step4",
   "metadata": {},
   "source": [
    "### 2.4 Test Scheduler Lifecycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_scheduler_lifecycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Check status\n",
    "status = get_scheduler_status()\n",
    "print(f\"Scheduler running: {status['running']}\")\n",
    "\n",
    "# Stop scheduler\n",
    "print(\"\\nStopping scheduler...\")\n",
    "stop_scheduler()\n",
    "time.sleep(1)\n",
    "status = get_scheduler_status()\n",
    "print(f\"âœ… Scheduler running: {status['running']}\")\n",
    "\n",
    "# Start again\n",
    "print(\"\\nStarting scheduler again...\")\n",
    "start_scheduler()\n",
    "time.sleep(1)\n",
    "status = get_scheduler_status()\n",
    "print(f\"âœ… Scheduler running: {status['running']}\")\n",
    "print(f\"   Jobs: {len(status['jobs'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cp2_summary",
   "metadata": {},
   "source": [
    "### âœ… Checkpoint 2 ì™„ë£Œ!\n",
    "\n",
    "- Scheduler ì´ˆê¸°í™” ë° ìƒíƒœ í™•ì¸\n",
    "- 3ê°œ scheduled jobs ë“±ë¡ (collect_data, process_articles, send_digests)\n",
    "- ê°œë³„ íƒœìŠ¤í¬ ìˆ˜ë™ ì‹¤í–‰\n",
    "- Scheduler start/stop ë¼ì´í”„ì‚¬ì´í´"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checkpoint3_header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Checkpoint 3: Full Pipeline Integration\n",
    "\n",
    "ì „ì²´ íŒŒì´í”„ë¼ì¸ (ìˆ˜ì§‘ â†’ ì²˜ë¦¬ â†’ ì €ì¥ â†’ íë ˆì´ì…˜ â†’ ë°œì†¡)ì„ End-to-endë¡œ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cp3_step1",
   "metadata": {},
   "source": [
    "### 3.1 Create Integration Test User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_integration_user",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create integration test user\n",
    "integration_user = crud.create_user(\n",
    "    db=db,\n",
    "    email=\"integration_test@example.com\",\n",
    "    name=\"Integration Test User\"\n",
    ")\n",
    "\n",
    "crud.create_user_preference(\n",
    "    db=db,\n",
    "    user_id=integration_user.id,\n",
    "    research_fields=[\"Machine Learning\", \"NLP\", \"Computer Vision\"],\n",
    "    keywords=[\"transformer\", \"attention\", \"LLM\", \"GPT\", \"BERT\"],\n",
    "    email_time=\"09:00\",\n",
    "    daily_limit=10,\n",
    "    email_enabled=False,\n",
    ")\n",
    "\n",
    "print(f\"âœ… Created integration test user: {integration_user.email}\")\n",
    "print(f\"   User ID: {integration_user.id}\")\n",
    "\n",
    "integration_user_id = integration_user.id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cp3_step2",
   "metadata": {},
   "source": [
    "### 3.2 Run Full Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run_full_pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running Full Pipeline Integration Test\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Data Collection\n",
    "print(\"\\n1ï¸âƒ£ Data Collection...\")\n",
    "initial_count = crud.count_articles(db)\n",
    "collect_data_task()\n",
    "after_collect = crud.count_articles(db)\n",
    "print(f\"   âœ… Collected: {after_collect - initial_count} articles\")\n",
    "\n",
    "# 2. Article Processing\n",
    "print(\"\\n2ï¸âƒ£ Article Processing...\")\n",
    "process_articles_task()\n",
    "print(f\"   âœ… Processing completed\")\n",
    "\n",
    "# 3. Database Statistics\n",
    "print(\"\\n3ï¸âƒ£ Database Statistics\")\n",
    "total = crud.count_articles(db)\n",
    "papers = crud.count_articles(db, source_type=\"paper\")\n",
    "news = crud.count_articles(db, source_type=\"news\")\n",
    "print(f\"   Total: {total} | Papers: {papers} | News: {news}\")\n",
    "\n",
    "# 4. Top Articles\n",
    "print(\"\\n4ï¸âƒ£ Top Articles by Importance\")\n",
    "top_articles = crud.get_top_articles_by_importance(db, limit=5)\n",
    "for i, article in enumerate(top_articles, 1):\n",
    "    print(f\"   {i}. [{article.importance_score:.3f}] {article.title[:50]}...\")\n",
    "\n",
    "# 5. Create Digest\n",
    "print(\"\\n5ï¸âƒ£ Digest Creation\")\n",
    "if len(top_articles) > 0:\n",
    "    digest = crud.create_digest(\n",
    "        db=db,\n",
    "        user_id=integration_user_id,\n",
    "        article_ids=[str(a.id) for a in top_articles],\n",
    "    )\n",
    "    print(f\"   âœ… Created digest: {len(digest.article_ids)} articles\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"âœ… Full Pipeline Integration Test Completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cp3_step3",
   "metadata": {},
   "source": [
    "### 3.3 Verify Relationships & Data Integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verify_integration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get user with all relationships\n",
    "user = crud.get_user_by_id(db, integration_user_id)\n",
    "\n",
    "print(\"User Relationships:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"User: {user.email}\")\n",
    "print(f\"âœ… Has preference: {user.preference is not None}\")\n",
    "if user.preference:\n",
    "    print(f\"   Research fields: {user.preference.research_fields}\")\n",
    "    print(f\"   Daily limit: {user.preference.daily_limit}\")\n",
    "\n",
    "print(f\"\\nâœ… Digests: {len(user.digests)}\")\n",
    "for digest in user.digests:\n",
    "    print(f\"   - {digest.sent_at}: {len(digest.article_ids)} articles\")\n",
    "\n",
    "print(f\"\\nâœ… Feedbacks: {len(user.feedbacks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cp3_step4",
   "metadata": {},
   "source": [
    "### 3.4 Pipeline Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "performance_metrics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "all_articles = crud.list_articles(db, limit=100)\n",
    "has_summary = sum(1 for a in all_articles if a.summary)\n",
    "has_score = sum(1 for a in all_articles if a.importance_score is not None)\n",
    "has_category = sum(1 for a in all_articles if a.category)\n",
    "has_vector = sum(1 for a in all_articles if a.vector_id)\n",
    "\n",
    "total = len(all_articles)\n",
    "\n",
    "print(\"ğŸ“ˆ Pipeline Performance Metrics\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Total articles: {total}\")\n",
    "print(f\"\\nProcessing completion rates:\")\n",
    "if total > 0:\n",
    "    print(f\"  Summarization: {has_summary}/{total} ({has_summary/total*100:.1f}%)\")\n",
    "    print(f\"  Importance scoring: {has_score}/{total} ({has_score/total*100:.1f}%)\")\n",
    "    print(f\"  Categorization: {has_category}/{total} ({has_category/total*100:.1f}%)\")\n",
    "    print(f\"  Embedding generation: {has_vector}/{total} ({has_vector/total*100:.1f}%)\")\n",
    "    \n",
    "    if has_score > 0:\n",
    "        avg_score = sum(a.importance_score for a in all_articles if a.importance_score) / has_score\n",
    "        print(f\"\\nAverage importance score: {avg_score:.3f}\")\n",
    "else:\n",
    "    print(\"  No articles to analyze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cp3_summary",
   "metadata": {},
   "source": [
    "### âœ… Checkpoint 3 ì™„ë£Œ!\n",
    "\n",
    "- ë°ì´í„° ìˆ˜ì§‘ (arXiv + News)\n",
    "- LLM ì²˜ë¦¬ (ìš”ì•½, í‰ê°€, ë¶„ë¥˜, ì„ë² ë”©)\n",
    "- ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ë° ê´€ê³„ ê²€ì¦\n",
    "- ë‹¤ì´ì œìŠ¤íŠ¸ íë ˆì´ì…˜\n",
    "- ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë¶„ì„"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checkpoint4_header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Checkpoint 4: Scheduler API & Monitoring\n",
    "\n",
    "REST APIë¥¼ í†µí•œ ìŠ¤ì¼€ì¤„ëŸ¬ ëª¨ë‹ˆí„°ë§ ë° ì œì–´ë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "**âš ï¸ ì£¼ì˜**: ì´ ì„¹ì…˜ì„ ì‹¤í–‰í•˜ê¸° ì „ì— FastAPI ì„œë²„ë¥¼ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "```bash\n",
    "# ë³„ë„ í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰\n",
    "uvicorn src.app.api.main:app --reload --port 8000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cp4_step1",
   "metadata": {},
   "source": [
    "### 4.1 Setup API Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup_api_client",
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "import json\n",
    "\n",
    "# API base URL\n",
    "BASE_URL = \"http://localhost:8000/api/scheduler\"\n",
    "\n",
    "print(\"âœ… API Client setup\")\n",
    "print(f\"   Base URL: {BASE_URL}\")\n",
    "\n",
    "# Test if server is running\n",
    "try:\n",
    "    response = httpx.get(\"http://localhost:8000/health\", timeout=2.0)\n",
    "    if response.status_code == 200:\n",
    "        print(\"âœ… FastAPI server is running\")\n",
    "    else:\n",
    "        print(f\"âš ï¸  Server returned: {response.status_code}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Could not connect to server: {e}\")\n",
    "    print(\"   Please start the FastAPI server first:\")\n",
    "    print(\"   uvicorn src.app.api.main:app --reload --port 8000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cp4_step2",
   "metadata": {},
   "source": [
    "### 4.2 Test GET /api/scheduler/status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_status_endpoint",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = httpx.get(f\"{BASE_URL}/status\")\n",
    "\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    print(\"\\nâœ… GET /status successful\\n\")\n",
    "    print(json.dumps(data, indent=2, ensure_ascii=False))\n",
    "    \n",
    "    print(f\"\\nScheduler Running: {data['running']}\")\n",
    "    print(f\"Timezone: {data['timezone']}\")\n",
    "    print(f\"Jobs: {len(data['jobs'])}\")\n",
    "else:\n",
    "    print(f\"âŒ Error: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cp4_step3",
   "metadata": {},
   "source": [
    "### 4.3 Test GET /api/scheduler/jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_jobs_endpoint",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = httpx.get(f\"{BASE_URL}/jobs\")\n",
    "\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    print(\"\\nâœ… GET /jobs successful\\n\")\n",
    "    \n",
    "    print(f\"Total Jobs: {data['total']}\\n\")\n",
    "    for i, job in enumerate(data['jobs'], 1):\n",
    "        print(f\"{i}. {job['name']}\")\n",
    "        print(f\"   ID: {job['id']}\")\n",
    "        print(f\"   Next Run: {job['next_run_time']}\")\n",
    "        print(f\"   Trigger: {job['trigger']}\")\n",
    "        print()\n",
    "else:\n",
    "    print(f\"âŒ Error: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cp4_step4",
   "metadata": {},
   "source": [
    "### 4.4 Test POST /api/scheduler/jobs/trigger (Optional)\n",
    "\n",
    "âš ï¸ **WARNING**: This will actually run the job! Uncomment only if you want to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_trigger_endpoint",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to test job triggering\n",
    "# job_id = 'collect_data'  # or 'process_articles' or 'send_digests'\n",
    "# payload = {'job_id': job_id}\n",
    "# response = httpx.post(f'{BASE_URL}/jobs/trigger', json=payload)\n",
    "# \n",
    "# print(f\"Status Code: {response.status_code}\")\n",
    "# if response.status_code == 200:\n",
    "#     data = response.json()\n",
    "#     print(\"\\nâœ… POST /jobs/trigger successful\\n\")\n",
    "#     print(json.dumps(data, indent=2, ensure_ascii=False))\n",
    "# else:\n",
    "#     print(f\"âŒ Error: {response.text}\")\n",
    "\n",
    "print(\"âš ï¸  Job trigger test is commented out.\")\n",
    "print(\"   Uncomment the code above to test manual job triggering.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cp4_step5",
   "metadata": {},
   "source": [
    "### 4.5 Test Error Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_error_handling",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing Error Handling\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test 1: Invalid job ID\n",
    "print(\"\\n1. Testing invalid job ID:\")\n",
    "response = httpx.post(\n",
    "    f\"{BASE_URL}/jobs/trigger\",\n",
    "    json={\"job_id\": \"invalid_job_id\"}\n",
    ")\n",
    "print(f\"   Status: {response.status_code}\")\n",
    "if response.status_code == 404:\n",
    "    print(\"   âœ… Correctly returned 404\")\n",
    "\n",
    "# Test 2: Invalid control action\n",
    "print(\"\\n2. Testing invalid control action:\")\n",
    "response = httpx.post(\n",
    "    f\"{BASE_URL}/control\",\n",
    "    json={\"action\": \"invalid_action\"}\n",
    ")\n",
    "print(f\"   Status: {response.status_code}\")\n",
    "if response.status_code == 400:\n",
    "    print(\"   âœ… Correctly returned 400\")\n",
    "\n",
    "# Test 3: Missing required field\n",
    "print(\"\\n3. Testing missing required field:\")\n",
    "response = httpx.post(\n",
    "    f\"{BASE_URL}/jobs/trigger\",\n",
    "    json={}\n",
    ")\n",
    "print(f\"   Status: {response.status_code}\")\n",
    "if response.status_code == 422:\n",
    "    print(\"   âœ… Correctly returned 422\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"âœ… Error handling tests completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cp4_step6",
   "metadata": {},
   "source": [
    "### 4.6 Verify API Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verify_api_docs",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"FastAPI Auto-Generated Documentation:\\n\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n1. Swagger UI (Interactive):\")\n",
    "print(\"   http://localhost:8000/docs\")\n",
    "print(\"\\n2. ReDoc (Alternative):\")\n",
    "print(\"   http://localhost:8000/redoc\")\n",
    "print(\"\\n3. OpenAPI JSON Schema:\")\n",
    "print(\"   http://localhost:8000/openapi.json\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# Test if docs are accessible\n",
    "try:\n",
    "    response = httpx.get(\"http://localhost:8000/docs\", follow_redirects=True, timeout=2.0)\n",
    "    if response.status_code == 200:\n",
    "        print(\"\\nâœ… API documentation is accessible!\")\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸  Documentation returned status code: {response.status_code}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ Could not access documentation: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cp4_summary",
   "metadata": {},
   "source": [
    "### âœ… Checkpoint 4 ì™„ë£Œ!\n",
    "\n",
    "- REST API ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„ (4ê°œ)\n",
    "  - GET /api/scheduler/status\n",
    "  - GET /api/scheduler/jobs\n",
    "  - POST /api/scheduler/jobs/trigger\n",
    "  - POST /api/scheduler/control\n",
    "- Pydantic ìŠ¤í‚¤ë§ˆ (7ê°œ)\n",
    "- ì—ëŸ¬ í•¸ë“¤ë§ (404, 400, 422)\n",
    "- API ë¬¸ì„œ ìë™ ìƒì„± (Swagger UI, ReDoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleanup_section",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Cleanup (Optional)\n",
    "\n",
    "í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to clean up test data\n",
    "# crud.delete_user(db, user_id)  # Cascade deletes preferences, digests, feedbacks\n",
    "# crud.delete_user(db, integration_user_id)\n",
    "# crud.delete_article(db, article1.id)\n",
    "# crud.delete_article(db, article2.id)\n",
    "# crud.delete_article(db, article3.id)\n",
    "# print(\"âœ… Test data deleted\")\n",
    "\n",
    "# Stop scheduler\n",
    "stop_scheduler()\n",
    "print(\"âœ… Scheduler stopped\")\n",
    "\n",
    "# Close database session\n",
    "db.close()\n",
    "print(\"âœ… Database session closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final_summary",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ‰ Day 7 ì „ì²´ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\n",
    "\n",
    "## í…ŒìŠ¤íŠ¸ ì™„ë£Œ í•­ëª©\n",
    "\n",
    "### âœ… Checkpoint 1: Database Models & CRUD\n",
    "- SQLAlchemy ëª¨ë¸ ê´€ê³„ ì„¤ì • (ForeignKey, CASCADE)\n",
    "- 40+ CRUD ì—°ì‚° êµ¬í˜„\n",
    "- User, UserPreference, CollectedArticle, SentDigest, Feedback\n",
    "\n",
    "### âœ… Checkpoint 2: Scheduler & Tasks\n",
    "- APScheduler ì„¤ì • ë° ë¼ì´í”„ì‚¬ì´í´\n",
    "- 3ê°œ scheduled jobs (ìˆ˜ì§‘, ì²˜ë¦¬, ë°œì†¡)\n",
    "- Retry ë¡œì§ ë° ì—ëŸ¬ í•¸ë“¤ë§\n",
    "\n",
    "### âœ… Checkpoint 3: Full Pipeline Integration\n",
    "- ë°ì´í„° ìˆ˜ì§‘ â†’ LLM ì²˜ë¦¬ â†’ ì €ì¥ â†’ íë ˆì´ì…˜\n",
    "- End-to-end íŒŒì´í”„ë¼ì¸ ê²€ì¦\n",
    "- ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë¶„ì„\n",
    "\n",
    "### âœ… Checkpoint 4: Scheduler API & Monitoring\n",
    "- REST API ì—”ë“œí¬ì¸íŠ¸ (4ê°œ)\n",
    "- Pydantic ìŠ¤í‚¤ë§ˆ (7ê°œ)\n",
    "- ì—ëŸ¬ í•¸ë“¤ë§ ë° API ë¬¸ì„œ ìë™ ìƒì„±\n",
    "\n",
    "## ì‹œìŠ¤í…œ ìƒíƒœ\n",
    "\n",
    "**âœ… Production Ready** (Vector DB integration pending)\n",
    "\n",
    "- Database: 5 models, 40+ CRUD operations, 6 relationships\n",
    "- Scheduler: 3 jobs, KST timezone, graceful shutdown\n",
    "- API: 4 REST endpoints, 7 Pydantic schemas\n",
    "- Pipeline: ìˆ˜ì§‘ â†’ ì²˜ë¦¬ â†’ ì €ì¥ â†’ íë ˆì´ì…˜ â†’ ë°œì†¡ â†’ ëª¨ë‹ˆí„°ë§\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Vector DB operations ì™„ì„±\n",
    "- Streamlit í”„ë¡ íŠ¸ì—”ë“œ êµ¬í˜„\n",
    "- ì‹¤ì œ SMTP ì´ë©”ì¼ ë°œì†¡ í…ŒìŠ¤íŠ¸\n",
    "- API ì¸ì¦ (JWT) ì¶”ê°€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
