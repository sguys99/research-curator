{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 5 í†µí•© í…ŒìŠ¤íŠ¸: Vector DB & Semantic Search\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ Day 5ì—ì„œ êµ¬í˜„í•œ Vector Databaseì™€ Semantic Search ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "## êµ¬í˜„ëœ ê¸°ëŠ¥\n",
    "1. âœ… Qdrant Vector DB ì—°ê²° ë° ì»¬ë ‰ì…˜ ê´€ë¦¬\n",
    "2. âœ… OpenAI ì„ë² ë”© ìƒì„± (ì¬ì‹œë„, í† í° ì œí•œ, ìºì‹±)\n",
    "3. âœ… Vector CRUD ì—°ì‚° (Create, Read, Update, Delete)\n",
    "4. âœ… Semantic Search (ìì—°ì–´ ê²€ìƒ‰, ìœ ì‚¬ ë¬¸ì„œ ì°¾ê¸°, í•„í„°ë§)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add project root to path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root / \"src\"))\n",
    "\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import asyncio\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "from app.vector_db import (\n",
    "    VectorOperations,\n",
    "    get_qdrant_client,\n",
    "    initialize_vector_db,\n",
    "    CollectionSchema,\n",
    ")\n",
    "from app.processors.embedder import TextEmbedder, get_embedder\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(levelname)s - %(message)s\")\n",
    "\n",
    "print(\"âœ… Imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Vector DB\n",
    "print(\"Initializing vector database...\")\n",
    "success = initialize_vector_db(recreate=True)\n",
    "\n",
    "if success:\n",
    "    print(\"âœ… Vector database initialized successfully\")\n",
    "else:\n",
    "    print(\"âŒ Failed to initialize vector database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Qdrant Client & Collection Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Qdrant connection\n",
    "client = get_qdrant_client()\n",
    "health = client.health_check()\n",
    "\n",
    "print(\"ğŸ¥ Qdrant Health Check:\")\n",
    "print(f\"  Status: {health['status']}\")\n",
    "print(f\"  Connected: {health['connected']}\")\n",
    "print(f\"  Host: {health['host']}:{health['port']}\")\n",
    "print(f\"  Collections: {health.get('collections', [])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get collection info\n",
    "info = client.get_collection_info()\n",
    "\n",
    "print(\"ğŸ“Š Collection Information:\")\n",
    "print(f\"  Name: {info['name']}\")\n",
    "print(f\"  Vector Size: {info['vector_size']}\")\n",
    "print(f\"  Points Count: {info['points_count']}\")\n",
    "print(f\"  Status: {info['status']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check schema\n",
    "schema_info = CollectionSchema.get_schema_info()\n",
    "\n",
    "print(\"ğŸ“‹ Collection Schema:\")\n",
    "print(f\"  Collection: {schema_info['collection_name']}\")\n",
    "print(f\"  Vector Size: {schema_info['vector_size']}\")\n",
    "print(f\"  Distance: {schema_info['distance_metric']}\")\n",
    "print(f\"\\n  Payload Fields:\")\n",
    "for field, dtype in schema_info['payload_schema'].items():\n",
    "    print(f\"    - {field}: {dtype}\")\n",
    "print(f\"\\n  Indexes: {len(schema_info['payload_indexes'])} fields indexed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Embedding Generation Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize embedder\n",
    "embedder = TextEmbedder(use_cache=True)\n",
    "\n",
    "print(f\"ğŸ“ Embedder Configuration:\")\n",
    "print(f\"  Model: {embedder.model}\")\n",
    "print(f\"  Max Tokens: {embedder.MAX_TOKENS}\")\n",
    "print(f\"  Cache Enabled: {embedder.use_cache}\")\n",
    "print(f\"  Embedding Dimension: {embedder.get_embedding_dimension()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test single embedding\n",
    "test_text = \"Transformer architecture for natural language processing\"\n",
    "\n",
    "# Generate embedding\n",
    "embedding = await embedder.embed(test_text)\n",
    "\n",
    "print(f\"Text: {test_text}\")\n",
    "print(f\"Tokens: {embedder.count_tokens(test_text)}\")\n",
    "print(f\"Embedding dimension: {len(embedding)}\")\n",
    "print(f\"First 5 values: {embedding[:5]}\")\n",
    "print(f\"Vector norm: {sum(x**2 for x in embedding) ** 0.5:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test batch embedding\n",
    "texts = [\n",
    "    \"Attention Is All You Need\",\n",
    "    \"BERT: Pre-training of Deep Bidirectional Transformers\",\n",
    "    \"GPT-4 Technical Report\",\n",
    "]\n",
    "\n",
    "embeddings = await embedder.batch_embed(texts, batch_size=3)\n",
    "\n",
    "print(f\"Batch Embedding Results:\")\n",
    "print(f\"  Total texts: {len(texts)}\")\n",
    "print(f\"  Total embeddings: {len(embeddings)}\")\n",
    "print(f\"\\nDetails:\")\n",
    "for i, (text, emb) in enumerate(zip(texts, embeddings), 1):\n",
    "    tokens = embedder.count_tokens(text)\n",
    "    print(f\"  [{i}] {text[:40]}... ({tokens} tokens, {len(emb)} dims)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cache\n",
    "print(\"Testing cache...\")\n",
    "emb1 = await embedder.embed(test_text)\n",
    "stats_before = embedder.get_cache_stats()\n",
    "\n",
    "emb2 = await embedder.embed(test_text)  # Should hit cache\n",
    "stats_after = embedder.get_cache_stats()\n",
    "\n",
    "print(f\"Cache before: {stats_before}\")\n",
    "print(f\"Cache after: {stats_after}\")\n",
    "print(f\"Cache hit (embeddings identical): {emb1 == emb2}\")\n",
    "print(f\"âœ… Cache working correctly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Vector CRUD Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize VectorOperations\n",
    "ops = VectorOperations()\n",
    "\n",
    "print(f\"VectorOperations initialized:\")\n",
    "print(f\"  Collection: {ops.collection_name}\")\n",
    "print(f\"  Current articles count: {ops.count_articles()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert single article\n",
    "article1 = {\n",
    "    \"article_id\": \"test-uuid-1\",\n",
    "    \"title\": \"Attention Is All You Need\",\n",
    "    \"content\": \"\"\"\n",
    "    The dominant sequence transduction models are based on complex recurrent\n",
    "    or convolutional neural networks. We propose a new simple network architecture,\n",
    "    the Transformer, based solely on attention mechanisms, dispensing with\n",
    "    recurrence and convolutions entirely.\n",
    "    \"\"\",\n",
    "    \"summary\": \"Transformer ì•„í‚¤í…ì²˜ë¥¼ ì œì•ˆí•˜ëŠ” í˜ì‹ ì ì¸ ë…¼ë¬¸ì…ë‹ˆë‹¤.\",\n",
    "    \"source_type\": \"paper\",\n",
    "    \"category\": \"NLP\",\n",
    "    \"importance_score\": 0.95,\n",
    "    \"metadata\": {\"authors\": [\"Vaswani et al.\"], \"year\": 2017},\n",
    "}\n",
    "\n",
    "vector_id1 = await ops.insert_article(**article1)\n",
    "\n",
    "print(f\"âœ… Inserted article:\")\n",
    "print(f\"  Title: {article1['title']}\")\n",
    "print(f\"  Vector ID: {vector_id1}\")\n",
    "print(f\"  Total articles: {ops.count_articles()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch insert articles\n",
    "articles_batch = [\n",
    "    {\n",
    "        \"article_id\": \"test-uuid-2\",\n",
    "        \"title\": \"BERT: Pre-training of Deep Bidirectional Transformers\",\n",
    "        \"content\": \"BERT obtains state-of-the-art results on eleven NLP tasks.\",\n",
    "        \"summary\": \"BERT ëª¨ë¸ì„ ì†Œê°œí•˜ëŠ” ë…¼ë¬¸ì…ë‹ˆë‹¤.\",\n",
    "        \"source_type\": \"paper\",\n",
    "        \"category\": \"NLP\",\n",
    "        \"importance_score\": 0.92,\n",
    "    },\n",
    "    {\n",
    "        \"article_id\": \"test-uuid-3\",\n",
    "        \"title\": \"GPT-4 Technical Report\",\n",
    "        \"content\": \"GPT-4 is a large-scale, multimodal model.\",\n",
    "        \"summary\": \"GPT-4ì˜ ê¸°ìˆ  ë¦¬í¬íŠ¸ì…ë‹ˆë‹¤.\",\n",
    "        \"source_type\": \"report\",\n",
    "        \"category\": \"AI\",\n",
    "        \"importance_score\": 0.98,\n",
    "    },\n",
    "    {\n",
    "        \"article_id\": \"test-uuid-4\",\n",
    "        \"title\": \"Efficient Transformers: A Survey\",\n",
    "        \"content\": \"A comprehensive overview of efficient Transformer models.\",\n",
    "        \"summary\": \"íš¨ìœ¨ì ì¸ Transformer ëª¨ë¸ë“¤ì„ ì¡°ì‚¬í•©ë‹ˆë‹¤.\",\n",
    "        \"source_type\": \"paper\",\n",
    "        \"category\": \"NLP\",\n",
    "        \"importance_score\": 0.88,\n",
    "    },\n",
    "    {\n",
    "        \"article_id\": \"test-uuid-5\",\n",
    "        \"title\": \"OpenAI Announces New AI Safety Research\",\n",
    "        \"content\": \"OpenAI focuses on AI alignment and safety research.\",\n",
    "        \"summary\": \"OpenAIì˜ AI ì•ˆì „ì„± ì—°êµ¬ ë°œí‘œì…ë‹ˆë‹¤.\",\n",
    "        \"source_type\": \"news\",\n",
    "        \"category\": \"AI Safety\",\n",
    "        \"importance_score\": 0.85,\n",
    "    },\n",
    "]\n",
    "\n",
    "vector_ids = await ops.insert_articles_batch(articles_batch, batch_size=2)\n",
    "\n",
    "print(f\"âœ… Batch inserted {len(vector_ids)} articles\")\n",
    "print(f\"  Vector IDs: {vector_ids[:2]}...\")\n",
    "print(f\"  Total articles: {ops.count_articles()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve article\n",
    "retrieved = ops.get_article(vector_id1)\n",
    "\n",
    "print(f\"Retrieved Article:\")\n",
    "print(f\"  Vector ID: {retrieved['vector_id']}\")\n",
    "print(f\"  Title: {retrieved['title']}\")\n",
    "print(f\"  Category: {retrieved['category']}\")\n",
    "print(f\"  Importance: {retrieved['importance_score']}\")\n",
    "print(f\"  Source Type: {retrieved['source_type']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update article\n",
    "update_success = await ops.update_article(\n",
    "    vector_id=vector_id1,\n",
    "    importance_score=0.99,\n",
    "    category=\"NLP/Transformers\",\n",
    ")\n",
    "\n",
    "updated = ops.get_article(vector_id1)\n",
    "\n",
    "print(f\"Update Result: {update_success}\")\n",
    "print(f\"Updated Article:\")\n",
    "print(f\"  Title: {updated['title']}\")\n",
    "print(f\"  Importance: {updated['importance_score']} (was 0.95)\")\n",
    "print(f\"  Category: {updated['category']} (was NLP)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Semantic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic semantic search\n",
    "query = \"transformer architecture and attention mechanism\"\n",
    "\n",
    "results = await ops.search_similar_articles(\n",
    "    query=query,\n",
    "    limit=3,\n",
    "    score_threshold=0.5,\n",
    ")\n",
    "\n",
    "print(f\"ğŸ” Search Query: '{query}'\")\n",
    "print(f\"Results found: {len(results)}\\n\")\n",
    "\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"[{i}] Score: {result['score']:.4f}\")\n",
    "    print(f\"    Title: {result['title']}\")\n",
    "    print(f\"    Category: {result['category']}\")\n",
    "    print(f\"    Type: {result['source_type']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search with filters\n",
    "query = \"artificial intelligence research\"\n",
    "\n",
    "print(f\"ğŸ” Query: '{query}'\\n\")\n",
    "\n",
    "# Papers only\n",
    "papers = await ops.search_similar_articles(\n",
    "    query=query,\n",
    "    limit=5,\n",
    "    source_type=[\"paper\"],\n",
    ")\n",
    "\n",
    "print(f\"ğŸ“„ Papers only: {len(papers)} results\")\n",
    "for r in papers:\n",
    "    print(f\"  - {r['title'][:50]}... (type: {r['source_type']})\")\n",
    "\n",
    "# News only\n",
    "news = await ops.search_similar_articles(\n",
    "    query=query,\n",
    "    limit=5,\n",
    "    source_type=[\"news\"],\n",
    ")\n",
    "\n",
    "print(f\"\\nğŸ“° News only: {len(news)} results\")\n",
    "for r in news:\n",
    "    print(f\"  - {r['title'][:50]}... (type: {r['source_type']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# High importance articles\n",
    "query = \"language models and NLP\"\n",
    "\n",
    "high_importance = await ops.search_similar_articles(\n",
    "    query=query,\n",
    "    limit=5,\n",
    "    min_importance_score=0.9,\n",
    ")\n",
    "\n",
    "print(f\"ğŸ” Query: '{query}'\")\n",
    "print(f\"â­ High importance (â‰¥0.9): {len(high_importance)} results\\n\")\n",
    "\n",
    "for r in high_importance:\n",
    "    print(f\"  - {r['title'][:45]}...\")\n",
    "    print(f\"    Score: {r['importance_score']}, Similarity: {r['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined filters\n",
    "query = \"transformer models\"\n",
    "\n",
    "results = await ops.search_similar_articles(\n",
    "    query=query,\n",
    "    limit=5,\n",
    "    score_threshold=0.5,\n",
    "    source_type=[\"paper\"],\n",
    "    category=[\"NLP\", \"NLP/Transformers\"],\n",
    "    min_importance_score=0.85,\n",
    ")\n",
    "\n",
    "print(f\"ğŸ” Query: '{query}'\")\n",
    "print(f\"ğŸ“‹ Filters: papers + NLP category + importanceâ‰¥0.85\")\n",
    "print(f\"Results: {len(results)}\\n\")\n",
    "\n",
    "for r in results:\n",
    "    print(f\"  - {r['title'][:45]}...\")\n",
    "    print(f\"    Type: {r['source_type']}, Category: {r['category']}\")\n",
    "    print(f\"    Importance: {r['importance_score']}, Similarity: {r['score']:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find similar articles\n",
    "similar = await ops.find_similar_articles(\n",
    "    vector_id=vector_id1,\n",
    "    limit=3,\n",
    "    score_threshold=0.5,\n",
    ")\n",
    "\n",
    "ref_article = ops.get_article(vector_id1)\n",
    "\n",
    "print(f\"ğŸ“š Reference Article:\")\n",
    "print(f\"  Title: {ref_article['title']}\")\n",
    "print(f\"  Category: {ref_article['category']}\")\n",
    "print(f\"\\nğŸ” Similar Articles: {len(similar)} found\\n\")\n",
    "\n",
    "for i, article in enumerate(similar, 1):\n",
    "    print(f\"[{i}] Score: {article['score']:.4f}\")\n",
    "    print(f\"    Title: {article['title']}\")\n",
    "    print(f\"    Category: {article['category']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Performance & Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collection statistics\n",
    "info = client.get_collection_info()\n",
    "\n",
    "print(\"ğŸ“Š Vector Database Statistics:\")\n",
    "print(f\"  Collection: {info['name']}\")\n",
    "print(f\"  Total Articles: {info['points_count']}\")\n",
    "print(f\"  Vector Dimension: {info['vector_size']}\")\n",
    "print(f\"  Status: {info['status']}\")\n",
    "print(f\"  Optimizer: {info['optimizer_status']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedder statistics\n",
    "cache_stats = embedder.get_cache_stats()\n",
    "\n",
    "print(\"ğŸ—„ï¸ Embedder Cache Statistics:\")\n",
    "print(f\"  Cache Size: {cache_stats['size']}\")\n",
    "print(f\"  Cache Enabled: {cache_stats['enabled']}\")\n",
    "print(f\"  Model: {cache_stats['model']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance test: Search speed\n",
    "import time\n",
    "\n",
    "test_queries = [\n",
    "    \"transformer architecture\",\n",
    "    \"natural language processing\",\n",
    "    \"machine learning models\",\n",
    "]\n",
    "\n",
    "print(\"âš¡ Search Performance Test:\\n\")\n",
    "\n",
    "for query in test_queries:\n",
    "    start = time.time()\n",
    "    results = await ops.search_similar_articles(query, limit=5)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    print(f\"  Query: '{query}'\")\n",
    "    print(f\"  Results: {len(results)}, Time: {elapsed*1000:.1f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cleanup (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete test articles (optional)\n",
    "# Uncomment to clean up\n",
    "\n",
    "# all_vector_ids = [vector_id1] + vector_ids\n",
    "# success = ops.delete_articles_batch(all_vector_ids)\n",
    "# print(f\"Deleted {len(all_vector_ids)} articles: {success}\")\n",
    "# print(f\"Remaining articles: {ops.count_articles()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear embedder cache\n",
    "embedder.clear_cache()\n",
    "print(f\"Cache cleared. Size: {embedder.get_cache_size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### âœ… Tested Features\n",
    "\n",
    "**1. Vector Database**\n",
    "- Qdrant connection and health check\n",
    "- Collection creation and management\n",
    "- Schema validation\n",
    "\n",
    "**2. Embedding Generation**\n",
    "- Single text embedding\n",
    "- Batch embedding\n",
    "- Token counting and truncation\n",
    "- Cache functionality\n",
    "\n",
    "**3. CRUD Operations**\n",
    "- Insert single article\n",
    "- Batch insert articles\n",
    "- Retrieve articles\n",
    "- Update articles\n",
    "- Delete articles\n",
    "\n",
    "**4. Semantic Search**\n",
    "- Natural language query search\n",
    "- Score threshold filtering\n",
    "- Source type filtering\n",
    "- Category filtering\n",
    "- Importance score filtering\n",
    "- Combined filters\n",
    "- Find similar articles\n",
    "\n",
    "### ğŸš€ Ready for Production\n",
    "\n",
    "ëª¨ë“  ê¸°ëŠ¥ì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ë©°, ì‹¤ì œ ì• í”Œë¦¬ì¼€ì´ì…˜ì— í†µí•©í•  ì¤€ë¹„ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
