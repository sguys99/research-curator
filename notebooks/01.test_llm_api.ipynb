{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM API Endpoints Test\n",
    "\n",
    "**IMPORTANT: Backend 서버를 사전에 기동해야 합니다.**\n",
    "\n",
    "```bash\n",
    "# Terminal에서 실행:\n",
    "uvicorn src.app.api.main:app --reload\n",
    "```\n",
    "\n",
    "Day1 작업 중에 FastAPI LLM 엔드포인트 기능 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Setup complete\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "from typing import Dict, List\n",
    "\n",
    "# API base URL\n",
    "BASE_URL = \"http://127.0.0.1:8000\"\n",
    "LLM_BASE = f\"{BASE_URL}/api/llm\"  # /api prefix 추가!\n",
    "\n",
    "print(\"✓ Setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Server is running and healthy!\n",
      "Response: {'status': 'healthy'}\n"
     ]
    }
   ],
   "source": [
    "# Server health check\n",
    "try:\n",
    "    response = requests.get(f\"http://127.0.0.1:8000/health\", timeout=5.0)\n",
    "    if response.status_code == 200:\n",
    "        print(\"✅ Server is running and healthy!\")\n",
    "        print(f\"Response: {response.json()}\")\n",
    "    else:\n",
    "        print(f\"⚠️ Server responded with status code: {response.status_code}\")\n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"❌ Cannot connect to server. Please start the backend:\")\n",
    "    print(\"   uvicorn src.app.api.main:app --reload\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Health check failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Basic Chat Completion\n",
    "\n",
    "기본적인 채팅 완성 기능 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI Response:\n",
      "Status Code: 200\n",
      "Full Response: {'content': '2024년 AI 분야에서 주목할 만한 5가지 키 트렌드는 다음과 같습니다:\\n\\n1. **Generative AI의 발전**: 생성적 적대 신경망(GAN) 및 대규모 언어 모델의 발전으로 더욱 정교하고 창의적인 콘텐츠 생성이 가능해질 것입니다. 텍스트, 이미지, 음악 등 다양한 분야에서 AI가 인간과 협력하여 콘텐츠를 생성하는 사례가 늘어날 것입니다.\\n\\n2. **AI의 윤리 및 규제 강화**: AI 기술의 발전과 함께 윤리적 문제와 사회적 책임에 대한 논의가 활발해질 것입니다. 많은 국가에서 AI 관련 규제와 윤리 가이드라인이 마련되고, 기업들은 이러한 기준을 준수하는 방향으로 나아가야 할 것입니다.\\n\\n3. **AI의 자동화 및 효율화**: 기업들은 AI를 활용하여 업무 프로세스를 자동화하고 효율성을 높이는 데 집중할 것입니다. 특히, 로봇 프로세스 자동화(RPA)와 결합된 AI 솔루션이 증가할 것으로 예상됩니다.\\n\\n4. **AI와 IoT의 통합**: 사물인터넷(IoT) 장치와 AI의 결합이 더욱 강화되어, 실시간 데이터 분석 및 의사결정 지원이 개선될 것입니다. 스마트 홈, 스마트 시티 등 다양한 분야에서 AI가 IoT 데이터를 활용하는 사례가 늘어', 'provider': 'openai', 'model': 'gpt-4o-mini', 'finish_reason': 'stop'}\n",
      "\n",
      "Provider: openai\n",
      "Model: gpt-4o-mini\n",
      "Content:\n",
      "2024년 AI 분야에서 주목할 만한 5가지 키 트렌드는 다음과 같습니다:\n",
      "\n",
      "1. **Generative AI의 발전**: 생성적 적대 신경망(GAN) 및 대규모 언어 모델의 발전으로 더욱 정교하고 창의적인 콘텐츠 생성이 가능해질 것입니다. 텍스트, 이미지, 음악 등 다양한 분야에서 AI가 인간과 협력하여 콘텐츠를 생성하는 사례가 늘어날 것입니다.\n",
      "\n",
      "2. **AI의 윤리 및 규제 강화**: AI 기술의 발전과 함께 윤리적 문제와 사회적 책임에 대한 논의가 활발해질 것입니다. 많은 국가에서 AI 관련 규제와 윤리 가이드라인이 마련되고, 기업들은 이러한 기준을 준수하는 방향으로 나아가야 할 것입니다.\n",
      "\n",
      "3. **AI의 자동화 및 효율화**: 기업들은 AI를 활용하여 업무 프로세스를 자동화하고 효율성을 높이는 데 집중할 것입니다. 특히, 로봇 프로세스 자동화(RPA)와 결합된 AI 솔루션이 증가할 것으로 예상됩니다.\n",
      "\n",
      "4. **AI와 IoT의 통합**: 사물인터넷(IoT) 장치와 AI의 결합이 더욱 강화되어, 실시간 데이터 분석 및 의사결정 지원이 개선될 것입니다. 스마트 홈, 스마트 시티 등 다양한 분야에서 AI가 IoT 데이터를 활용하는 사례가 늘어\n"
     ]
    }
   ],
   "source": [
    "# OpenAI 채팅 완성 테스트\n",
    "request_data = {\n",
    "    \"provider\": \"openai\",\n",
    "    \"model\": \"gpt-4o-mini\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful AI research assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"2024년 AI 분야 키 트렌드 5가지를 알려줘.\"},\n",
    "    ],\n",
    "    \"temperature\": 0.7,\n",
    "    \"max_tokens\": 300,\n",
    "}\n",
    "\n",
    "response = requests.post(f\"{LLM_BASE}/chat/completions\", json=request_data)\n",
    "\n",
    "print(\"OpenAI Response:\")\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "\n",
    "# 먼저 전체 응답을 확인\n",
    "result = response.json()\n",
    "print(f\"Full Response: {result}\")\n",
    "print()\n",
    "\n",
    "# 성공적인 응답인 경우에만 필드 출력\n",
    "if response.status_code == 200 and \"provider\" in result:\n",
    "    print(f\"Provider: {result['provider']}\")\n",
    "    print(f\"Model: {result['model']}\")\n",
    "    print(f\"Content:\\n{result['content']}\")\n",
    "else:\n",
    "    print(\"Error occurred:\")\n",
    "    print(f\"Response: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Claude Chat Completion\n",
    "\n",
    "Claude API를 사용한 채팅 완성을 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claude Response:\n",
      "Status Code: 200\n",
      "Provider: claude\n",
      "Model: claude-sonnet-4-5-20250929\n",
      "Content:\n",
      "# 2024년 AI 분야 주요 트렌드 5가지\n",
      "\n",
      "## 1. **생성형 AI의 멀티모달 진화**\n",
      "- 텍스트, 이미지, 음성, 비디오를 통합 처리하는 멀티모달 AI 확산\n",
      "- GPT-4V, Gemini 등 여러 형태의 데이터를 동시에 이해하고 생성\n",
      "- 실용적 응용 분야 확대 (디자인, 교육, 콘텐츠 제작)\n",
      "\n",
      "## 2. **온디바이스 AI (Edge AI)**\n",
      "- 클라우드 의존도를 낮춘 로컬 디바이스 기반 AI 처리 증가\n",
      "- 스마트폰, PC에서 직접 실행되는 경량화 모델 (Apple Silicon, Snapdragon)\n",
      "- 개인정보 보호와 응답 속도 개선\n",
      "\n",
      "## 3. **AI 에이전트와 자동화**\n",
      "- 단순 응답을 넘어\n"
     ]
    }
   ],
   "source": [
    "# Claude 채팅 완성 테스트 (API 키가 설정된 경우에만)\n",
    "try:\n",
    "    request_data = {\n",
    "        \"provider\": \"claude\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": \"2024년 AI 분야 키 트렌드 5가지를 알려줘.\"}],\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": 300,\n",
    "    }\n",
    "\n",
    "    response = requests.post(f\"{LLM_BASE}/chat/completions\", json=request_data)\n",
    "    result = response.json()\n",
    "\n",
    "    print(\"Claude Response:\")\n",
    "    print(f\"Status Code: {response.status_code}\")\n",
    "    print(f\"Provider: {result['provider']}\")\n",
    "    print(f\"Model: {result['model']}\")\n",
    "    print(f\"Content:\\n{result['content']}\")\n",
    "except Exception as e:\n",
    "    print(f\"Claude API not available: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. JSON Response Format\n",
    "\n",
    "JSON 형식의 응답을 요청하고 파싱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON Response:\n",
      "{\n",
      "    \"category\": \"news\",\n",
      "    \"importance_score\": 0.9,\n",
      "    \"keywords\": [\"GPT-5\", \"human-level performance\", \"complex reasoning\", \"AI\", \"machine learning\"],\n",
      "    \"summary\": \"GPT-5 has reached human-level performance on complex reasoning tasks, marking a significant milestone in AI development.\"\n",
      "}\n",
      "\n",
      "Parsed Data:\n",
      "{\n",
      "  \"category\": \"news\",\n",
      "  \"importance_score\": 0.9,\n",
      "  \"keywords\": [\n",
      "    \"GPT-5\",\n",
      "    \"human-level performance\",\n",
      "    \"complex reasoning\",\n",
      "    \"AI\",\n",
      "    \"machine learning\"\n",
      "  ],\n",
      "  \"summary\": \"GPT-5 has reached human-level performance on complex reasoning tasks, marking a significant milestone in AI development.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "request_data = {\n",
    "    \"provider\": \"openai\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that responds in JSON format.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\"\n",
    "            기사 타이틀을 분석하고 다음 기준으로 JSON 포맷으로 정리해줘:\n",
    "            - category: one of (paper, news, report)\n",
    "            - importance_score: 0.0 to 1.0\n",
    "            - keywords: list of 3-5 relevant keywords\n",
    "            - summary: brief one-line summary\n",
    "\n",
    "            Title: \"GPT-5 Achieves Human-Level Performance on Complex Reasoning Tasks\"\n",
    "            \"\"\",\n",
    "        },\n",
    "    ],\n",
    "    \"response_format\": \"json\",\n",
    "    \"max_tokens\": 300,\n",
    "}\n",
    "\n",
    "response = requests.post(f\"{LLM_BASE}/chat/completions\", json=request_data)\n",
    "result = response.json()\n",
    "\n",
    "print(\"JSON Response:\")\n",
    "print(result['content'])\n",
    "\n",
    "# Parse JSON\n",
    "data = json.loads(result['content'])\n",
    "print(\"\\nParsed Data:\")\n",
    "print(json.dumps(data, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Article Summarization (Korean)\n",
    "\n",
    "논문을 한국어로 요약하는 기능을 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Korean Summary:\n",
      "Summary: MIT 연구진이 트랜스포머의 장점과 합성곱 신경망의 효율성을 결합한 새로운 신경망 구조를 개발했습니다. 이 하이브리드 모델, TransConv는 이미지 분류 작업에서 최첨단 결과를 달성하면서도 기존 트랜스포머 모델보다 40% 적은 계산 자원을 필요로 합니다. 주요 혁신은 입력 특성에 따라 지역적 및 전역적 특징 처리를 선택적으로 수행하는 주의 메커니즘에 있습니다.\n",
      "Original Length: 517 characters\n",
      "Summary Length: 204 characters\n"
     ]
    }
   ],
   "source": [
    "article_text = \"\"\"\n",
    "Researchers at MIT have developed a new neural network architecture\n",
    "that combines the benefits of transformers with the efficiency of\n",
    "convolutional neural networks. The hybrid model, dubbed TransConv,\n",
    "achieves state-of-the-art results on image classification tasks while\n",
    "requiring 40% less computational resources than traditional transformer\n",
    "models. The key innovation lies in the selective attention mechanism\n",
    "that adaptively chooses between local and global feature processing\n",
    "based on the input characteristics.\n",
    "\"\"\"\n",
    "\n",
    "request_data = {\n",
    "    \"provider\": \"openai\",\n",
    "    \"title\": \"TransConv: Hybrid Architecture for Efficient Image Classification\",\n",
    "    \"content\": article_text,\n",
    "    \"language\": \"ko\",\n",
    "    \"max_sentences\": 4,\n",
    "}\n",
    "\n",
    "response = requests.post(f\"{LLM_BASE}/summarize\", json=request_data)\n",
    "result = response.json()\n",
    "\n",
    "print(\"Korean Summary:\")\n",
    "print(f\"Summary: {result['summary']}\")\n",
    "print(f\"Original Length: {result['original_length']} characters\")\n",
    "print(f\"Summary Length: {result['summary_length']} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Embedding Generation\n",
    "\n",
    "텍스트 임베딩을 생성하고 유사도를 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 4 embeddings\n",
      "Embedding dimension: 1536\n",
      "First embedding (first 5 values): [-0.030603239312767982, -0.06797607243061066, 0.004770813975483179, -0.015896877273917198, 0.019433407112956047]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 여러 텍스트의 임베딩 생성\n",
    "texts = [\n",
    "    \"Transformer architecture in deep learning\",\n",
    "    \"Attention mechanism for neural networks\",\n",
    "    \"Reinforcement learning for robotics\",\n",
    "    \"Computer vision using CNNs\",\n",
    "]\n",
    "\n",
    "embeddings = []\n",
    "for text in texts:\n",
    "    request_data = {\"text\": text}\n",
    "    response = requests.post(f\"{LLM_BASE}/embeddings\", json=request_data)\n",
    "    result = response.json()\n",
    "    embeddings.append(result['embedding'])\n",
    "\n",
    "print(f\"Generated {len(embeddings)} embeddings\")\n",
    "print(f\"Embedding dimension: {len(embeddings[0])}\")\n",
    "print(f\"First embedding (first 5 values): {embeddings[0][:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cosine Similarities:\n",
      "'Transformer architecture in deep learning' vs 'Attention mechanism for neural networks': 0.4854\n",
      "'Transformer architecture in deep learning' vs 'Reinforcement learning for robotics': 0.3041\n",
      "'Transformer architecture in deep learning' vs 'Computer vision using CNNs': 0.4224\n",
      "'Attention mechanism for neural networks' vs 'Reinforcement learning for robotics': 0.3289\n",
      "'Attention mechanism for neural networks' vs 'Computer vision using CNNs': 0.3612\n",
      "'Reinforcement learning for robotics' vs 'Computer vision using CNNs': 0.3520\n"
     ]
    }
   ],
   "source": [
    "# 코사인 유사도 계산\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "\n",
    "print(\"\\nCosine Similarities:\")\n",
    "for i, text_i in enumerate(texts):\n",
    "    for j, text_j in enumerate(texts):\n",
    "        if i < j:\n",
    "            similarity = cosine_similarity(embeddings[i], embeddings[j])\n",
    "            print(f\"'{text_i}' vs '{text_j}': {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Temperature Comparison\n",
    "\n",
    "다양한 temperature 값에 따른 응답 차이를 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature Comparison:\n",
      "Prompt: Explain neural networks in one sentence.\n",
      "\n",
      "Temperature 0.0:\n",
      "  Neural networks are computational models inspired by the human brain, consisting of interconnected layers of nodes (neurons) that process and learn from data to perform tasks such as classification, regression, and pattern recognition.\n",
      "\n",
      "Temperature 0.5:\n",
      "  Neural networks are computational models inspired by the human brain's interconnected neuron structure, designed to recognize patterns and solve complex problems through layers of interconnected nodes.\n",
      "\n",
      "Temperature 1.0:\n",
      "  Neural networks are computational models inspired by the human brain, consisting of layers of interconnected nodes (neurons) that process input data to recognize patterns and make decisions or predictions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temperatures = [0.0, 0.5, 1.0]\n",
    "prompt = \"Explain neural networks in one sentence.\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "]\n",
    "\n",
    "print(\"Temperature Comparison:\")\n",
    "print(f\"Prompt: {prompt}\\n\")\n",
    "\n",
    "for temp in temperatures:\n",
    "    request_data = {\n",
    "        \"provider\": \"openai\",\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": temp,\n",
    "        \"max_tokens\": 100,\n",
    "    }\n",
    "\n",
    "    response = requests.post(f\"{LLM_BASE}/chat/completions\", json=request_data)\n",
    "    result = response.json()\n",
    "\n",
    "    print(f\"Temperature {temp}:\")\n",
    "    print(f\"  {result['content']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Error Handling\n",
    "\n",
    "에러 처리를 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 422\n",
      "Error: {'detail': [{'type': 'literal_error', 'loc': ['body', 'provider'], 'msg': \"Input should be 'openai' or 'claude'\", 'input': 'invalid', 'ctx': {'expected': \"'openai' or 'claude'\"}}]}\n",
      "\n",
      "Response with large max_tokens received (API handled it)\n"
     ]
    }
   ],
   "source": [
    "# Test invalid provider\n",
    "try:\n",
    "    request_data = {\n",
    "        \"provider\": \"invalid\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}],\n",
    "    }\n",
    "    response = requests.post(f\"{LLM_BASE}/chat/completions\", json=request_data)\n",
    "    print(f\"Status Code: {response.status_code}\")\n",
    "    print(f\"Error: {response.json()}\")\n",
    "except Exception as e:\n",
    "    print(f\"✓ Caught expected error for invalid provider: {e}\")\n",
    "\n",
    "# Test with very large max_tokens\n",
    "try:\n",
    "    request_data = {\n",
    "        \"provider\": \"openai\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}],\n",
    "        \"max_tokens\": 100000,\n",
    "    }\n",
    "    response = requests.post(f\"{LLM_BASE}/chat/completions\", json=request_data)\n",
    "    if response.status_code == 500:\n",
    "        print(f\"\\n✓ Error with large max_tokens: {response.json()['detail']}\")\n",
    "    else:\n",
    "        print(\"\\nResponse with large max_tokens received (API handled it)\")\n",
    "except Exception as e:\n",
    "    print(f\"Error with large max_tokens: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Article Analysis\n",
    "\n",
    "연구 논문 분석 파이프라인 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research Article Analysis Result:\n",
      "{\n",
      "  \"category\": \"paper\",\n",
      "  \"importance_score\": 1.0,\n",
      "  \"keywords\": [\n",
      "    \"Transformer\",\n",
      "    \"attention mechanism\",\n",
      "    \"sequence transduction\",\n",
      "    \"neural networks\",\n",
      "    \"encoder-decoder\"\n",
      "  ],\n",
      "  \"field\": \"NLP\",\n",
      "  \"summary_korean\": \"이 논문은 기존의 복잡한 순환 신경망이나 합성곱 신경망을 사용하는 인코더-디코더 구조 대신, 주의 메커니즘만을 기반으로 한 새로운 간단한 네트워크 아키텍처인 트랜스포머를 제안합니다. 트랜스포머는 순환이나 합성곱을 완전히 배제하고 주의 메커니즘을 통해 인코더와 디코더를 연결하여 성능을 향상시킵니다. 이를 통해 더 효율적이고 단순한 모델 구조를 제공합니다.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "test_article = {\n",
    "    \"title\": \"Attention Is All You Need\",\n",
    "    \"content\": \"\"\"\n",
    "    The dominant sequence transduction models are based on complex recurrent or\n",
    "    convolutional neural networks in an encoder-decoder configuration. The best\n",
    "    performing models also connect the encoder and decoder through an attention\n",
    "    mechanism. We propose a new simple network architecture, the Transformer,\n",
    "    based solely on attention mechanisms, dispensing with recurrence and convolutions\n",
    "    entirely.\n",
    "    \"\"\",\n",
    "}\n",
    "\n",
    "request_data = {\n",
    "    \"provider\": \"openai\",\n",
    "    \"title\": test_article[\"title\"],\n",
    "    \"content\": test_article[\"content\"],\n",
    "}\n",
    "\n",
    "response = requests.post(f\"{LLM_BASE}/analyze\", json=request_data)\n",
    "result = response.json()\n",
    "\n",
    "print(\"Research Article Analysis Result:\")\n",
    "print(json.dumps(result, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Batch Processing\n",
    "\n",
    "여러 문서를 동시에 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Processing Results:\n",
      "\n",
      "1. Title: GPT-5 Improvements\n",
      "   Original: GPT-5 shows remarkable improvements in reasoning capabilities.\n",
      "   Summary: GPT-5는 추론 능력에서 눈에 띄는 향상을 보입니다. 이 모델은 복잡한 문제 해결과 논리적 사고에서 특히 강점을 나타내고 있습니다.\n",
      "\n",
      "2. Title: New Transformer\n",
      "   Original: New transformer architecture reduces computational costs by 40%.\n",
      "   Summary: 새로운 트랜스포머 아키텍처는 계산 비용을 40% 절감합니다. 이로 인해 효율적인 모델 구현이 가능해졌습니다.\n",
      "\n",
      "3. Title: RL Breakthrough\n",
      "   Original: Reinforcement learning breakthrough enables better robot control.\n",
      "   Summary: 강화 학습의 혁신적 발전으로 로봇 제어가 향상되었습니다. 이 기술은 로봇의 효율성과 정밀성을 크게 개선하는 데 기여합니다.\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "\n",
    "def summarize_article(article_info):\n",
    "    \"\"\"단일 논문 요약\"\"\"\n",
    "    title, content = article_info\n",
    "    request_data = {\n",
    "        \"provider\": \"openai\",\n",
    "        \"title\": title,\n",
    "        \"content\": content,\n",
    "        \"language\": \"ko\",\n",
    "        \"max_sentences\": 2,\n",
    "    }\n",
    "    response = requests.post(f\"{LLM_BASE}/summarize\", json=request_data)\n",
    "    return response.json()[\"summary\"]\n",
    "\n",
    "\n",
    "# Test batch processing\n",
    "articles = [\n",
    "    (\"GPT-5 Improvements\", \"GPT-5 shows remarkable improvements in reasoning capabilities.\"),\n",
    "    (\n",
    "        \"New Transformer\",\n",
    "        \"New transformer architecture reduces computational costs by 40%.\",\n",
    "    ),\n",
    "    (\n",
    "        \"RL Breakthrough\",\n",
    "        \"Reinforcement learning breakthrough enables better robot control.\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "# 병렬 처리\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
    "    summaries = list(executor.map(summarize_article, articles))\n",
    "\n",
    "print(\"Batch Processing Results:\")\n",
    "for i, ((title, content), summary) in enumerate(zip(articles, summaries, strict=False), 1):\n",
    "    print(f\"\\n{i}. Title: {title}\")\n",
    "    print(f\"   Original: {content}\")\n",
    "    print(f\"   Summary: {summary}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "이 노트북에서 다룬 내용:\n",
    "\n",
    "1. ✓ Basic chat completion (OpenAI & Claude)\n",
    "2. ✓ JSON response format\n",
    "3. ✓ Korean summarization\n",
    "4. ✓ Embedding generation and similarity\n",
    "5. ✓ Temperature comparison\n",
    "6. ✓ Error handling\n",
    "7. ✓ Article analysis\n",
    "8. ✓ Batch processing\n",
    "\n",
    "LLM API 엔드포인트가 정상적으로 작동하며, 다양한 사용 사례에 활용할 수 있습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
