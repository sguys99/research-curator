# AI 연구자를 위한 맞춤형 리서치 큐레이션 서비스

## 📋 프로젝트 개요

### 서비스 소개
연구자들이 각자의 분야에서 최신 글로벌 자료, 리포트, 뉴스, 논문을 일일이 찾아다니는 번거로움을 해결하는 AI 기반 자동 큐레이션 서비스입니다. LLM과 웹 검색 기술을 활용하여 특정 연구 분야의 트렌드 정보를 주기적으로 수집하고, 한국어로 요약하여 이메일로 전송합니다.

### 핵심 문제 정의
- 연구자들은 논문, 뉴스, 리포트 등 여러 소스에서 정보를 수집하기 위해 매일 반복적인 매뉴얼 작업 수행
- 개별 서비스 접속, 검색, 링크 클릭 등의 시간 소모적 작업
- 중요한 정보를 놓칠 위험

### 솔루션
주기적으로 사용자 맞춤형 정보를 자동 수집 및 큐레이션하여 이메일로 전송함으로써, 연구자들이 핵심 정보에만 집중할 수 있도록 지원

---

## 🎯 타겟 사용자

### PoC 단계
- **대상**: AI 연구자 (기업 연구소 / AI 개발자)
- **규모**: 10명
- **초점**: 해외 최신 정보 중 "놓치면 안 되는" 핵심 정보

### 확장 계획
- 사용자가 요구사항을 입력하면 특정 연구 분야 서비스 제공
- 연구자 레벨별 맞춤 콘텐츠 제공 (대학원생, 박사후연구원, 교수 등)

---

## 💎 핵심 가치 제안

### 차별점

| 기존 서비스 | 우리 서비스 |
|------------|------------|
| Google Scholar, arXiv alerts 등 개별 서비스 | 통합 플랫폼 |
| 사용자가 직접 각 서비스 방문 및 검색 | 자동 수집 및 큐레이션 |
| 매뉴얼 작업 반복 | 완전 자동화 |
| 원문 그대로 | AI 한국어 요약 |
| **일회성 정보 소비** | **검색된 모든 자료 영구 저장 및 재활용** |
| **과거 자료는 다시 찾기 어려움** | **언제든지 시맨틱 검색으로 빠른 재검색** |
| **자료 간 연결성 파악 불가** | **AI 기반 자료 간 유사성 분석 및 관계 정리** |

### 핵심 차별화 요소

**1. 지속적인 지식 축적**
- 매일 수집되는 모든 자료를 Vector DB에 저장
- 시간이 지날수록 사용자만의 맞춤형 리서치 아카이브 구축
- 데이터가 쌓일수록 가치가 증가하는 구조

**2. 언제든 재검색 가능**
- "3개월 전에 받았던 transformer 최적화 논문 찾아줘"
- 자연어 검색으로 과거 자료 즉시 접근
- 시맨틱 검색으로 정확한 키워드 없이도 관련 자료 발견

**3. 자료 간 관계 파악**
- 유사한 주제의 논문들 자동 그룹핑
- 연구 트렌드 변화 추적
- 특정 주제에 대한 시간순 발전 과정 파악
- 서로 다른 출처의 관련 정보 연결

**4. 지식 재활용**
- 과거에 받은 정보를 새로운 맥락에서 재발견
- 프로젝트 시작 시 관련 과거 자료 일괄 검색
- 보고서 작성 시 참고 자료 빠른 수집

### 큐레이션 기준
1. **화제성**: 현재 업계에서 주목받는 주제
2. **혁신성**: 새로운 접근법이나 획기적인 결과
3. **인용수**: 학술적 영향력 (논문의 경우)

### 정보 제공 주기
- **기본**: 매일
- **확장**: 사용자가 주기 설정 가능 (주간, 격주 등)

---

## ✨ 주요 기능

### 1. AI 대화형 온보딩
사용자와 AI가 대화를 주고받으며 필요한 정보를 수집
- 관심 연구 분야 / 키워드
- 선호하는 정보 유형 (논문/뉴스/리포트 비중)
- 검색을 원하는 사이트 주소
- 기타 맞춤 설정

### 2. 자동 데이터 수집
**기본 소스**
- **논문**: arXiv, Google Scholar, PubMed
- **뉴스**: TechCrunch, VentureBeat, MIT Technology Review
- **리포트**: 주요 리서치 기관

**커스터마이징**
- 사용자가 소스 추가/제거 가능
- 특정 저널이나 사이트 우선순위 설정

### 3. LLM 기반 처리
- **요약 생성**: 각 자료의 핵심 내용을 한국어로 요약
- **중요도 평가**: LLM 평가 + 메타데이터 기반 혼합 방식
  - 화제성, 혁신성 분석
  - 인용수, 출처 신뢰도 등 메타데이터 활용
- **카테고리 분류**: 논문/뉴스/리포트 자동 분류

### 4. 이메일 전송
**발송 시간**
- 기본: 매일 오전 8시
- 사용자 설정 가능

**콘텐츠 구성**
```
[섹션 1: 논문] 중요도 순
  ⭐⭐⭐ 제목
  📝 요약
  🔗 출처 링크

[섹션 2: 뉴스] 중요도 순
  ...

[섹션 3: 리포트] 중요도 순
  ...

⚙️ 설정 변경 | 💬 피드백
```

**제공량**
- 기본: 상위 5개
- 확장: 사용자 설정 가능, 임계값 기반 필터링

### 5. Vector DB 기반 검색 엔진
- 수집된 모든 자료를 Vector DB에 저장
- 웹 대시보드에서 과거 자료 시맨틱 검색
- 유사 자료 추천
- 정보 관리 및 트렌드 분석

### 6. 웹 대시보드
- 설정 관리 (관심사, 소스, 발송 시간 등)
- 과거 자료 검색
- 피드백 제출

### 7. 피드백 시스템
- 이메일 내 유용도 평가
- 별도 DB에 저장 및 관리
- 추후 추천 알고리즘 개선에 활용

---

## 🏗️ 기술 아키텍처

### 기술 스택

**백엔드**
- Language: Python
- Framework: FastAPI
- Database: PostgreSQL
- Vector DB: Qdrant (Docker 로컬 설치)
- Scheduler: APScheduler / Celery Beat

**LLM**
- Primary: GPT-4
- Framework: LiteLLM (모델 교체 가능하도록)
- Embedding: OpenAI (한국어 성능 고려)

**프론트엔드**
- Framework: Streamlit (PoC용, 빠른 개발)
- 추후: React로 전환 가능

**데이터 수집**
- 검색 API 활용 (Serper, Brave Search 등)
- 소스별 맞춤 크롤링 (점진적 개선)

**이메일**
- HTML 템플릿 기반
- SMTP 서버 연동

**배포**
- PoC: 로컬 서버
- 추후: AWS

### 시스템 아키텍처 다이어그램

```
[사용자]
    ↓ (온보딩/설정)
[Streamlit Web App] ← → [FastAPI Backend]
                            ↓
                    [PostgreSQL DB]
                            ↓
                    [Scheduler (매일 01:00)]
                            ↓
            ┌───────────────┴───────────────┐
            ↓                               ↓
    [데이터 수집]                      [Qdrant Vector DB]
    (검색 API, 크롤링)                 (임베딩 저장)
            ↓
    [LLM 처리]
    (요약, 평가, 분류)
            ↓
    [이메일 발송 (08:00)]
            ↓
        [사용자]
```

---

## 🔄 시스템 워크플로우

### 일일 자동화 파이프라인

**01:00 - 데이터 수집 시작**
1. 스케줄러 트리거
2. 각 사용자의 설정 로드
3. 설정된 소스에서 데이터 수집
   - 검색 API 호출
   - 웹 크롤링
   - 실패 시 N번 재시도 후 스킵

**01:30 - 데이터 처리**
4. 수집된 데이터 전처리 및 중복 제거
5. LLM 처리
   - 각 자료 요약 생성 (한국어)
   - 중요도 평가 (LLM + 메타데이터)
   - 카테고리 분류
6. Vector DB에 임베딩 저장

**06:00 - 콘텐츠 생성**
7. 사용자별 상위 N개 선정
8. HTML 이메일 템플릿 생성
   - 섹션별 구성 (논문/뉴스/리포트)
   - 섹션 내 중요도 순 정렬

**08:00 - 이메일 발송**
9. 각 사용자에게 이메일 전송
10. 발송 이력 DB 저장

**상시 - 사용자 인터랙션**
- 웹 대시보드 접속 (설정 변경, 검색)
- 피드백 제출
- 매직 링크 인증

---

## 🗄️ 데이터베이스 설계

### PostgreSQL 스키마

**Users**
```sql
- id: UUID (PK)
- email: String (Unique)
- name: String
- created_at: Timestamp
- last_login: Timestamp
```

**UserPreferences**
```sql
- id: UUID (PK)
- user_id: UUID (FK → Users)
- research_fields: JSON (관심 연구 분야)
- keywords: JSON (키워드 리스트)
- sources: JSON (소스 사이트 목록)
- info_types: JSON (논문/뉴스/리포트 비중)
- email_time: Time (발송 시간)
- daily_limit: Integer (일일 제공 개수)
- updated_at: Timestamp
```

**CollectedArticles**
```sql
- id: UUID (PK)
- title: String
- content: Text
- summary: Text (LLM 생성 요약)
- source_url: String
- source_type: Enum (paper/news/report)
- category: String
- importance_score: Float
- metadata: JSON (인용수, 저자, 날짜 등)
- collected_at: Timestamp
- vector_id: String (Qdrant 참조)
```

**SentDigests**
```sql
- id: UUID (PK)
- user_id: UUID (FK → Users)
- article_ids: JSON (발송된 기사 ID 리스트)
- sent_at: Timestamp
- email_opened: Boolean
```

**Feedback**
```sql
- id: UUID (PK)
- user_id: UUID (FK → Users)
- article_id: UUID (FK → CollectedArticles)
- rating: Integer (1-5)
- comment: Text
- created_at: Timestamp
```

### Qdrant Vector DB
```
Collection: research_articles
- vector: [embedding dimensions]
- payload:
  - article_id: UUID
  - title: String
  - summary: Text
  - metadata: JSON
```

---

## 🎨 UI/UX 설계

### 사용자 인증
**매직 링크 (Magic Link)**
- 비밀번호 없는 간편 인증
- 이메일로 로그인 링크 발송
- JWT 토큰 기반 세션 관리
- PoC에 최적화된 방식

### 온보딩 플로우
1. 이메일 입력 및 매직 링크 발송
2. 링크 클릭 → 자동 로그인
3. AI 챗봇과 대화형 온보딩
   - "어떤 분야를 연구하시나요?"
   - "주요 관심 키워드는 무엇인가요?"
   - "어떤 유형의 정보를 원하시나요? (논문/뉴스/리포트)"
   - "특별히 포함하고 싶은 사이트가 있나요?"
4. 설정 완료 → 다음날부터 이메일 수신

### 웹 대시보드 (Streamlit)
**메인 페이지**
- 설정 요약 정보
- 최근 받은 이메일 미리보기
- 빠른 설정 변경

**설정 관리**
- 관심 분야/키워드 수정
- 소스 추가/제거
- 발송 시간 변경
- 일일 제공량 조절

**검색 기능**
- 검색창: 자연어 쿼리
- 결과: 관련도 순 정렬
- 각 결과: 제목/요약/출처/날짜

**피드백 이력**
- 과거 피드백 조회
- 통계 확인

### 이메일 템플릿 (HTML)
```html
<!-- 헤더 -->
[서비스명] 오늘의 AI 연구 동향
📅 2025.11.22

<!-- 섹션 1: 논문 -->
📚 논문 (2건)

[1] ⭐⭐⭐ 중요도: 높음
제목: ...
요약: ...
🔗 원문 보기

<!-- 섹션 2: 뉴스 -->
📰 뉴스 (2건)
...

<!-- 섹션 3: 리포트 -->
📊 리포트 (1건)
...

<!-- 푸터 -->
⚙️ 설정 변경 | 💬 피드백 남기기
```

---

## 📅 개발 일정 (12일)

### Week 1: 핵심 백엔드 (Day 1-6)

**Day 1: 인프라 셋업**
- FastAPI 프로젝트 초기화
- PostgreSQL, Qdrant Docker 설정
- LiteLLM 연동 테스트
- 기본 프로젝트 구조 설계

**Day 2: 인증 시스템**
- 매직 링크 인증 구현
- JWT 토큰 관리
- 사용자 DB 스키마 생성
- 기본 API 엔드포인트

**Day 3: 데이터 수집 파이프라인**
- 검색 API 연동 (Serper/Brave)
- 기본 소스 크롤러 구현
- 데이터 수집 모듈 구조화
- 재시도 로직 구현

**Day 4: LLM 통합**
- LiteLLM 설정 (GPT-4)
- 프롬프트 엔지니어링
  - 요약 생성
  - 중요도 평가
  - 카테고리 분류
- 배치 처리 최적화

**Day 5: Vector DB**
- Qdrant 스키마 설계
- 임베딩 생성 (OpenAI)
- 벡터 저장 파이프라인
- 시맨틱 검색 구현

**Day 6: 이메일 시스템**
- HTML 템플릿 디자인
- SMTP 연동
- 발송 로직 구현
- 이메일 테스트

### Week 2: 프론트엔드 & 통합 (Day 7-11)

**Day 7: Streamlit 온보딩**
- AI 챗봇 인터페이스
- 대화형 설정 수집
- 사용자 프리퍼런스 저장
- 온보딩 플로우 테스트

**Day 8: Streamlit 대시보드**
- 설정 관리 UI
- 검색 인터페이스
- 피드백 제출 폼
- 전체 UI 통합

**Day 9: 데이터 처리 파이프라인 완성**
- 수집 → 처리 → 저장 통합
- LLM 배치 처리 최적화
- 에러 핸들링 강화
- 로깅 시스템 구축

**Day 10: 스케줄러 & 자동화**
- APScheduler 설정
- 01:00 데이터 수집 스케줄
- 08:00 이메일 발송 스케줄
- 전체 파이프라인 연결 테스트

**Day 11: 테스트 & 디버깅**
- End-to-end 테스트
- 엣지 케이스 처리
- 성능 최적화
- 버그 수정

### Day 12: 최종 점검 & 배포

- 전체 시스템 통합 테스트
- 10명 테스트 사용자 온보딩
- 모니터링 대시보드 설정
- 문서화 (README, API 문서)

---

## 📊 성공 지표

### 정량적 지표

**1. 시스템 안정성**
- 목표: 12일간 매일 정상 발송률 **90% 이상**
- 측정: 발송 성공/실패 로그 분석

**2. 정보 품질**
- 사용자 피드백 평균 점수 (1-5점)
- 목표: **3.5점 이상**

**3. 커버리지**
- 주요 AI 뉴스/논문 포함률
- 업계 주요 이슈 반영 여부
- 목표: 주요 이슈 **80% 이상** 포함

### 정성적 지표

**1. 사용자 만족도**
- 서비스 사용 의향
- 동료 추천 의향 (NPS)

**2. 실제 업무 도움**
- 정보 수집 시간 단축 체감
- 중요 정보 놓침 감소 체감
- 업무 효율성 개선 여부

### 측정 방법
- 매일 이메일 발송 이력 로깅
- 주간 피드백 설문조사
- PoC 종료 후 심층 인터뷰

---

## 🚀 확장 계획

### Phase 1: PoC (현재)
- AI 연구자 10명
- 기본 기능 검증
- 12일 개발

### Phase 2: 베타 (3개월)
- **다양한 연구 분야 지원**
  - 사용자가 분야 직접 설정
  - 분야별 소스 자동 매칭

- **사용자별 커스터마이징 강화**
  - 소스 추가/제거
  - 발송 시간 자유 설정
  - 임계값 기반 필터링

- **검색 기능 고도화**
  - 고급 필터 (날짜, 카테고리, 중요도)
  - 유사 자료 추천
  - 트렌드 분석 대시보드

- **피드백 루프**
  - 피드백 기반 알고리즘 개선
  - 개인화 추천 강화

### Phase 3: 정식 출시 (6개월)
- **사용자 레벨별 맞춤**
  - 대학원생: 기초 논문 + 튜토리얼
  - 박사후연구원: 최신 연구 + 컨퍼런스
  - 교수: 트렌드 + 펀딩 정보

- **협업 기능**
  - 팀 단위 구독
  - 공유 리서치 라이브러리

- **고급 분석**
  - 연구 트렌드 예측
  - 영향력 있는 연구자 추적
  - 협업 네트워크 분석

- **멀티 채널**
  - Slack, Discord 통합
  - 모바일 앱

- **AWS 배포**
  - Auto-scaling
  - 고가용성 아키텍처
  - 글로벌 CDN

---

## ⚠️ 위험 요소 및 대응 방안

### 기술적 위험

**1. 특정 소스 크롤링 차단/제한**
- 위험: Rate limiting, IP 차단
- 대응:
  - API 우선 사용
  - Rate limiting 준수
  - 여러 IP 로테이션 (추후)
  - 재시도 로직 + 백오프 전략

**2. LLM 응답 품질 편차**
- 위험: 요약 품질 불균일, 중요도 평가 오류
- 대응:
  - 프롬프트 엔지니어링 지속 개선
  - Few-shot 예시 추가
  - 재시도 로직 (품질 검증 실패 시)
  - 피드백 기반 프롬프트 튜닝

**3. 이메일 스팸 처리**
- 위험: 발송한 이메일이 스팸함으로 분류
- 대응:
  - SPF, DKIM, DMARC 설정
  - 신뢰할 수 있는 이메일 서비스 사용
  - 사용자에게 화이트리스트 안내

**4. Vector DB 성능**
- 위험: 데이터 증가 시 검색 속도 저하
- 대응:
  - 인덱스 최적화
  - 정기적인 벡터 재생성
  - 샤딩 전략 (확장 시)

### 일정 위험

**1. 12일 타이트한 일정**
- 위험: 예상치 못한 기술적 이슈로 지연
- 대응:
  - 우선순위 명확화 (핵심 파이프라인 먼저)
  - UI 최소화 (Streamlit)
  - 일일 마일스톤 체크
  - 기능 축소 가능성 준비

**2. 통합 이슈**
- 위험: 각 모듈 간 통합 시 예상치 못한 문제
- 대응:
  - Day 10에 통합 시간 확보
  - 모듈별 인터페이스 명확히 정의
  - 지속적인 통합 테스트

### 비즈니스 위험

**1. 사용자 채택률**
- 위험: 테스트 사용자들이 실제로 사용하지 않음
- 대응:
  - 사전 사용자 인터뷰로 니즈 검증
  - 온보딩 간소화
  - 초기 피드백 적극 반영

**2. 정보 과부하**
- 위험: 너무 많은 정보 제공으로 오히려 부담
- 대응:
  - 상위 5개로 제한
  - 중요도 기반 엄격한 필터링
  - 사용자 피드백 기반 조정

### 법적/윤리적 위험

**1. 저작권 이슈**
- 위험: 콘텐츠 요약/재배포 저작권 문제
- 대응:
  - 요약만 제공, 원문은 링크로
  - Fair use 원칙 준수
  - 출처 명확히 표기

**2. 개인정보 보호**
- 위험: 사용자 데이터 유출
- 대응:
  - 최소한의 개인정보만 수집
  - 데이터 암호화
  - GDPR 준수 (추후)

---

## 💡 추가 고려사항

### 모니터링 & 로깅
- 시스템 상태 대시보드
- 에러 알림 (이메일/Slack)
- 성능 메트릭 추적
- 사용자 행동 분석

### 확장성
- 마이크로서비스 아키텍처 전환 고려
- 메시지 큐 도입 (RabbitMQ, Kafka)
- 캐싱 전략 (Redis)
- CDN 활용

### 보안
- API 인증/인가
- Rate limiting
- SQL Injection 방지
- XSS 방지

### 비용 최적화
- LLM API 호출 최적화 (배치 처리)
- 캐싱으로 중복 요청 방지
- 임베딩 재사용
- 무료 티어 활용

---

## 📞 연락처 및 참고자료

### 프로젝트 정보
- **개발 기간**: 12일
- **개발자**: 1인
- **초기 사용자**: AI 개발자 10명

### 참고 기술 문서
- [FastAPI](https://fastapi.tiangolo.com/)
- [LiteLLM](https://docs.litellm.ai/)
- [Qdrant](https://qdrant.tech/documentation/)
- [Streamlit](https://docs.streamlit.io/)

---

**최종 업데이트**: 2025.11.22
